{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain\n!pip install langchain_community\n!pip install openai\n!pip install tiktoken","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile qwen.env\n## Qwen base_url\nOPENAI_BASE_URL='https://dashscope.aliyuncs.com/compatible-mode/v1'\nDASHSCOPE_API_KEY='sk-d4c3f773af5d442c97eb7d9e40479c55'\nOPENAI_API_KEY=${DASHSCOPE_API_KEY}","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:01:45.604149Z","iopub.execute_input":"2024-08-05T14:01:45.604596Z","iopub.status.idle":"2024-08-05T14:01:45.614135Z","shell.execute_reply.started":"2024-08-05T14:01:45.604561Z","shell.execute_reply":"2024-08-05T14:01:45.611815Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Writing qwen.env\n","output_type":"stream"}]},{"cell_type":"code","source":"## 使用qwen key\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv('qwen.env',override=True)\n\nimport os\nprint(os.environ['OPENAI_BASE_URL'],os.environ['OPENAI_API_KEY'])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:01:51.744882Z","iopub.execute_input":"2024-08-05T14:01:51.745296Z","iopub.status.idle":"2024-08-05T14:01:51.775310Z","shell.execute_reply.started":"2024-08-05T14:01:51.745263Z","shell.execute_reply":"2024-08-05T14:01:51.773996Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"https://dashscope.aliyuncs.com/compatible-mode/v1 sk-d4c3f773af5d442c97eb7d9e40479c55\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## langchains.memory\nLangChain 提供了多种储存类型。其中，\n- 缓冲区储存允许保留最近的**聊天消息**\n- 摘要储存则提供了对**整个对话的摘要**。\n- 实体储存则允许在多轮对话中保留有关**特定实体的信息**。\n这些记忆组件都是模块化的，可与其他组件组合使用，从而增强机器人的对话管理能力。\n\n### 四种常用的存储模块\n**使用方法：**建立一个存储模块，然后传参到ConversationChain中即可。\n\n#### 1.对话缓存储存 (buffer.ConversationBufferMemory）\n当我们在使用大型语言模型进行聊天对话时，大型语言模型本身实际上是无状态的。语言模型本身并不记得到目前为止的历史对话。每次调用API结点都是独立的。**储存(Memory)可以储存到目前为止的所有术语或对话，并将其输入或附加上下文到LLM中用于生成输出**。如此看起来就好像它在进行下一轮对话的时候，记得之前说过什么。\n\n#### 2.对话缓存窗口储存 (buffer_window.ConversationBufferWindowMemory）\n随着对话变得越来越长，所需的内存量也变得非常长。将大量的tokens发送到LLM的成本，也会变得更加昂贵，这也就是为什么API的调用费用，通常是基于它需要处理的tokens数量而收费的。针对以上问题，LangChain也提供了几种方便的储存方式来保存历史对话。其中，对话缓存窗口储存只保留一个窗口大小的对话。**它只使用最近的n次交互。这可以用于保持最近交互的滑动窗口，以便缓冲区不会过大**。\n\n#### 3.对话令牌缓存储存 (token_buffer.ConversationTokenBufferMemory）\n使用对话字符缓存记忆，**内存将限制保存的token数量**。如果字符数量超出指定数目，它会切掉这个对话的早期部分 以保留与最近的交流相对应的字符数量，但不超过字符限制。\n\n#### 4.对话摘要缓存储存 (summary.ConversationSummaryBufferMemory）\n对话摘要缓存储存，**使用 LLM 对到目前为止历史对话自动总结摘要**，并将其保存下来。","metadata":{}},{"cell_type":"markdown","source":"#### ConversationBufferMemory","metadata":{}},{"cell_type":"code","source":"from langchain.chains import ConversationChain\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.memory.buffer import ConversationBufferMemory\n\nmodel_name='qwen2-7b-instruct'\nllm = ChatOpenAI(model=model_name,temperature=0.0)  \n\nmemory = ConversationBufferMemory()\n\n# 新建一个 ConversationChain Class 实例\n# verbose参数设置为True时，程序会输出更详细的信息，以提供更多的调试或运行时信息。\n# 相反，当将verbose参数设置为False时，程序会以更简洁的方式运行，只输出关键的信息。\nconversation = ConversationChain(llm=llm, memory = memory, verbose=True)\nconversation","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:19:02.582291Z","iopub.execute_input":"2024-08-05T14:19:02.582838Z","iopub.status.idle":"2024-08-05T14:19:02.625021Z","shell.execute_reply.started":"2024-08-05T14:19:02.582801Z","shell.execute_reply":"2024-08-05T14:19:02.623623Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"ConversationChain(verbose=True, llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f142d00be50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f142d01e560>, model_name='qwen2-7b-instruct', temperature=0.0, openai_api_key='sk-d4c3f773af5d442c97eb7d9e40479c55', openai_proxy=''))"},"metadata":{}}]},{"cell_type":"code","source":"## 进行多轮对话\nconversation.verbose=False\noutput=conversation.predict(input=\"你好, 我叫皮皮鲁\")\n#print(output)\noutput=conversation.predict(input=\"1+1等于多少？\")\n#print(output)\nconversation.verbose=True\noutput=conversation.predict(input=\"我叫什么名字？\")\nprint(output)\n\nprint('memory:')\nprint(conversation.memory.buffer)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:19:06.113142Z","iopub.execute_input":"2024-08-05T14:19:06.113568Z","iopub.status.idle":"2024-08-05T14:19:09.002121Z","shell.execute_reply.started":"2024-08-05T14:19:06.113533Z","shell.execute_reply":"2024-08-05T14:19:09.000884Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nHuman: 你好, 我叫皮皮鲁\nAI: 你好，皮皮鲁！很高兴见到你。作为一个AI，我能够回答各种问题，提供信息和进行对话。有什么我可以帮助你的吗？\nHuman: 1+1等于多少？\nAI: 1+1等于2。\nHuman: 我叫什么名字？\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n你刚才提到你叫皮皮鲁。所以，你的名字是皮皮鲁。\nmemory:\nHuman: 你好, 我叫皮皮鲁\nAI: 你好，皮皮鲁！很高兴见到你。作为一个AI，我能够回答各种问题，提供信息和进行对话。有什么我可以帮助你的吗？\nHuman: 1+1等于多少？\nAI: 1+1等于2。\nHuman: 我叫什么名字？\nAI: 你刚才提到你叫皮皮鲁。所以，你的名字是皮皮鲁。\n","output_type":"stream"}]},{"cell_type":"code","source":"print(memory.load_memory_variables({}))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:05:03.217555Z","iopub.execute_input":"2024-08-05T14:05:03.217999Z","iopub.status.idle":"2024-08-05T14:05:03.224391Z","shell.execute_reply.started":"2024-08-05T14:05:03.217968Z","shell.execute_reply":"2024-08-05T14:05:03.223158Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'history': 'Human: 你好, 我叫皮皮鲁\\nAI: 你好，皮皮鲁！很高兴见到你。作为一个AI，我能够回答各种问题，提供信息和进行对话。有什么我可以帮助你的吗？\\nHuman: 1+1等于多少？\\nAI: 1+1等于2。这是最基本的数学加法。\\nHuman: 我叫什么名字？\\nAI: 你刚才说你叫皮皮鲁。所以，你的名字是皮皮鲁。'}\n","output_type":"stream"}]},{"cell_type":"code","source":"## 也可手动将对话添加到memory中\nmemory = ConversationBufferMemory()\nmemory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\nmemory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\nmemory.load_memory_variables({})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:21:28.511842Z","iopub.execute_input":"2024-08-05T14:21:28.512306Z","iopub.status.idle":"2024-08-05T14:21:28.521858Z","shell.execute_reply.started":"2024-08-05T14:21:28.512269Z","shell.execute_reply":"2024-08-05T14:21:28.520756Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'history': 'Human: 你好，我叫皮皮鲁\\nAI: 你好啊，我叫鲁西西\\nHuman: 很高兴和你成为朋友！\\nAI: 是的，让我们一起去冒险吧！'}"},"metadata":{}}]},{"cell_type":"markdown","source":"#### ConversationBufferWindowMemory","metadata":{}},{"cell_type":"code","source":"from langchain.memory.buffer_window import ConversationBufferWindowMemory\n\n# k=1表明只保留一个对话记忆\nmemory = ConversationBufferWindowMemory(k=1)  \nmemory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\nmemory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\nmemory.load_memory_variables({})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:30:42.266926Z","iopub.execute_input":"2024-08-05T14:30:42.267323Z","iopub.status.idle":"2024-08-05T14:30:42.277149Z","shell.execute_reply.started":"2024-08-05T14:30:42.267293Z","shell.execute_reply":"2024-08-05T14:30:42.275793Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"{'history': 'Human: 很高兴和你成为朋友！\\nAI: 是的，让我们一起去冒险吧！'}"},"metadata":{}}]},{"cell_type":"code","source":"llm = ChatOpenAI(model=model_name,temperature=0.0)\nmemory = ConversationBufferWindowMemory(k=1)\nconversation = ConversationChain(llm=llm, memory=memory, verbose=False  )\n\nprint(\"第一轮对话：\")\nprint(conversation.predict(input=\"你好, 我叫皮皮鲁\"))\n\nprint(\"第二轮对话：\")\nprint(conversation.predict(input=\"1+1等于多少？\"))\n\nprint(\"第三轮对话：\")\nprint(conversation.predict(input=\"我叫什么名字？\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:23:27.154809Z","iopub.execute_input":"2024-08-05T14:23:27.155196Z","iopub.status.idle":"2024-08-05T14:23:30.479886Z","shell.execute_reply.started":"2024-08-05T14:23:27.155169Z","shell.execute_reply":"2024-08-05T14:23:30.478642Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"第一轮对话：\n你好，皮皮鲁！很高兴见到你。作为一个AI，我能够帮助你解答问题、提供信息或者进行有趣的对话。请问有什么我可以帮助你的吗？\n第二轮对话：\n1+1等于2。这是最基本的数学加法。\n第三轮对话：\n作为一个AI，我并没有直接访问你个人信息的能力，因此无法告诉你你的名字。如果你愿意告诉我，我很乐意听到。不过，记得个人信息的安全和隐私是非常重要的哦！\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### ConversationTokenBufferMemory","metadata":{}},{"cell_type":"code","source":"from langchain.llms import OpenAI\nfrom langchain.memory.token_buffer import ConversationTokenBufferMemory\nllm=ChatOpenAI(\n    model='gpt-3.5-turbo',\n    temperature=0.0,\n    base_url='https://threefive.gpt7.link/v1',\n    openai_api_key='sk-7INmRu6iHEope6cJCa462b608aFb4eE281Df64F4E32e95F9'\n)  \n## 只会保留最后30个tokens\nmemory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\nmemory.save_context({\"input\": \"朝辞白帝彩云间，\"}, {\"output\": \"千里江陵一日还。\"})\nmemory.save_context({\"input\": \"两岸猿声啼不住，\"}, {\"output\": \"轻舟已过万重山。\"})\nmemory.load_memory_variables({})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:35:20.282794Z","iopub.execute_input":"2024-08-05T14:35:20.283258Z","iopub.status.idle":"2024-08-05T14:35:20.327765Z","shell.execute_reply.started":"2024-08-05T14:35:20.283223Z","shell.execute_reply":"2024-08-05T14:35:20.326614Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"{'history': 'AI: 轻舟已过万重山。'}"},"metadata":{}}]},{"cell_type":"markdown","source":"#### ConversationSummaryBufferMemory","metadata":{}},{"cell_type":"code","source":"from langchain.chains import ConversationChain\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.memory.summary_buffer import ConversationSummaryBufferMemory\n\n# 创建一个长字符串\nschedule = \"在八点你和你的产品团队有一个会议。 \\\n你需要做一个PPT。 \\\n上午9点到12点你需要忙于LangChain。\\\nLangchain是一个有用的工具，因此你的项目进展的非常快。\\\n中午，在意大利餐厅与一位开车来的顾客共进午餐 \\\n走了一个多小时的路程与你见面，只为了解最新的 AI。 \\\n确保你带了笔记本电脑可以展示最新的 LLM 样例.\"\n\nllm=ChatOpenAI(\n    model='gpt-3.5-turbo',\n    temperature=0.0,\n    base_url='https://threefive.gpt7.link/v1',\n    openai_api_key='sk-7INmRu6iHEope6cJCa462b608aFb4eE281Df64F4E32e95F9'\n)  \n## 设置summary的最大长度\nmemory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\nmemory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\nmemory.save_context({\"input\": \"很高兴和你成为朋友！\"}, {\"output\": \"是的，让我们一起去冒险吧！\"})\nmemory.save_context({\"input\": \"今天的日程安排是什么？\"}, {\"output\": f\"{schedule}\"})\n\nprint(memory.load_memory_variables({})['history'])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:38:28.303608Z","iopub.execute_input":"2024-08-05T14:38:28.304044Z","iopub.status.idle":"2024-08-05T14:38:32.620069Z","shell.execute_reply.started":"2024-08-05T14:38:28.304009Z","shell.execute_reply":"2024-08-05T14:38:32.618898Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"System: The human introduces themselves as 皮皮鲁, and the AI introduces itself as 鲁西西. They express happiness at becoming friends and discuss their agenda for the day. The AI informs the human about a meeting with their product team at 8 AM, during which they need to prepare a PPT. It mentions that from 9 AM to 12 PM, the human will be busy with LangChain, a useful tool that significantly aids their project’s progress. At noon, the human has a lunch meeting with a customer at an Italian restaurant, where they will discuss the latest in AI, reminding them to bring a laptop to showcase the newest LLM examples.\n","output_type":"stream"}]},{"cell_type":"code","source":"conversation = ConversationChain(llm=llm, memory=memory, verbose=True)\nconversation.predict(input=\"展示什么样的样例最好呢？\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:38:39.085621Z","iopub.execute_input":"2024-08-05T14:38:39.086035Z","iopub.status.idle":"2024-08-05T14:38:47.636586Z","shell.execute_reply.started":"2024-08-05T14:38:39.086004Z","shell.execute_reply":"2024-08-05T14:38:47.635406Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nSystem: The human introduces themselves as 皮皮鲁, and the AI introduces itself as 鲁西西. They express happiness at becoming friends and discuss their agenda for the day. The AI informs the human about a meeting with their product team at 8 AM, during which they need to prepare a PPT. It mentions that from 9 AM to 12 PM, the human will be busy with LangChain, a useful tool that significantly aids their project’s progress. At noon, the human has a lunch meeting with a customer at an Italian restaurant, where they will discuss the latest in AI, reminding them to bring a laptop to showcase the newest LLM examples.\nHuman: 展示什么样的样例最好呢？\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"'展示最新的大型语言模型（LLM）示例时，可以考虑以下几种类型的样例：\\n\\n1. **对话生成**：展示模型如何进行自然对话，比如模拟客服对话或伙伴聊天，这能让客户看到其在自然语言处理中的应用。\\n\\n2. **文本摘要**：使用模型对长篇文章进行自动摘要，快速提炼关键信息，展示其在信息处理方面的能力。\\n\\n3. **内容生成**：展示模型如何生成创意写作、新闻报道或技术文档，突出其创造性和适应性。\\n\\n4. **问答系统**：演示模型如何回答特定领域的问题，例如医疗、法律或科技相关的问题，体现其专业性和准确性。\\n\\n5. **翻译实例**：展示模型提供的翻译服务，突出其多语言支持能力，这在国际化项目中尤为重要。\\n\\n确保准备好相关的实际案例或数据，以便在展示时具体说明模型的准确性和实用性！如果你还有其他想法或者需要进一步的建议，随时告诉我哦！'"},"metadata":{}}]},{"cell_type":"code","source":"## 摘要记录会自动更新\nprint(memory.load_memory_variables({}))  ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:39:19.170607Z","iopub.execute_input":"2024-08-05T14:39:19.171026Z","iopub.status.idle":"2024-08-05T14:39:19.177644Z","shell.execute_reply.started":"2024-08-05T14:39:19.170997Z","shell.execute_reply":"2024-08-05T14:39:19.176153Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"{'history': \"System: The human introduces themselves as 皮皮鲁, and the AI introduces itself as 鲁西西. They express happiness at becoming friends and discuss their agenda for the day, including a product team meeting at 8 AM where they need to prepare a PPT. The human will be busy with LangChain from 9 AM to 12 PM, and they have a lunch meeting with a customer at an Italian restaurant at noon to discuss AI, where the human needs to bring their laptop to showcase the latest LLM examples. The human inquires about the best types of examples to present, and the AI suggests several, including dialogue generation, text summarization, content creation, question-answering systems, and translation examples, emphasizing the importance of having actual cases or data to illustrate the model's precision and practicality during the presentation.\"}\n","output_type":"stream"}]}]}