## SFT作用
指令微调旨在指导模型学会理解自然语言指令，并据此完成相应的任务。通过指令微调，大模型能够获得**较好的指令遵循与任务求解能力**，无需下游任务的训练样本或者示例就可以解决训练中未见过的任务。指令微调还可以缓解预训练阶段大模型会出现的一些常见问题，例如生成重复内容或者仅仅补全输入而不解决相关任务。
通用的大语言模型能够在传统自然语言处理任务（如生成和推理）以及日常生活任务（如头脑风暴）上取得较好的效果，然而它们在特定领域中（如医学、法律和金融等）的表现与领域专用模型的效果仍有一定差距。在实际应用中，**可以针对大语言模型进行面向特定领域的指令微调，从而使之能够适配下游的任务**。


## SFT训练策略
- 目标函数：用的目标函数为序列到序列损失，仅在输出部分计算损失，而**不计算输入部分的损失**。
- 批次大小和学习率. 考虑到预训练阶段已经学习到了能够展现较好性能的模型参数，指令微调阶段通常只需要使用**较小的批次大小和学习率对模型进行小幅度的调整**。

#### 数据组织策略

- 平衡数据分布：**现有的单一指令数据集通常只能增强大语言模型某些方面的能力，而无法提升模型的全方位能力**。因此，研究者通常建议混合使用现有的多个指令数据集，以此来实现模型能力的综合改进。
  - 研究者建议混合使用 NLP 任务数据（如 FLAN v2）、对话数据合成数据（如 GPT4-Alpaca），来进行大模型的指令微调。
- 多阶段指令数据微调：三种常用的指令微调数据，包括 NLP 任务数据、日常对话数据和合成数据。**由于这些指令数据数量不同且内容差异较大，需要在训练中对于这些数据资源进行有效的调度**，进而达到较好的训练效果。
- 结合预训练数据与指令微调数据：为了使得微调过程更加有效和稳定，**可以在指令微调期间引入了预训练数据和任务**，这可以看作是对于指令微调的**正则化**。