{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Qwen","metadata":{}},{"cell_type":"code","source":"!pip install dashscope","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-02T06:51:02.783140Z","iopub.execute_input":"2024-07-02T06:51:02.783529Z","iopub.status.idle":"2024-07-02T06:51:15.723112Z","shell.execute_reply.started":"2024-07-02T06:51:02.783499Z","shell.execute_reply":"2024-07-02T06:51:15.721640Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting dashscope\n  Downloading dashscope-1.20.0-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from dashscope) (3.9.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from dashscope) (2.32.3)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from dashscope) (1.7.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->dashscope) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->dashscope) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->dashscope) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->dashscope) (2024.2.2)\nDownloading dashscope-1.20.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: dashscope\nSuccessfully installed dashscope-1.20.0\n","output_type":"stream"}]},{"cell_type":"code","source":"my_qwen_key='sk-d4c3f773af5d442c97eb7d9e40479c55'","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:51:32.055956Z","iopub.execute_input":"2024-07-02T06:51:32.056350Z","iopub.status.idle":"2024-07-02T06:51:32.062159Z","shell.execute_reply.started":"2024-07-02T06:51:32.056317Z","shell.execute_reply":"2024-07-02T06:51:32.060850Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import dashscope\ndashscope.api_key='sk-d4c3f773af5d442c97eb7d9e40479c55'","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:53:35.503307Z","iopub.execute_input":"2024-07-02T06:53:35.503697Z","iopub.status.idle":"2024-07-02T06:53:35.508451Z","shell.execute_reply.started":"2024-07-02T06:53:35.503668Z","shell.execute_reply":"2024-07-02T06:53:35.507340Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom http import HTTPStatus\nimport dashscope\nimport os\n\ndef sample_sync_call():\n    # 在这里设置问题\n    prompt_text = 'The sky is'\n    resp = dashscope.Generation.call(\n        # 在这里指定模型名称\n        model='qwen-turbo',\n        prompt=prompt_text\n    )\n    # 如果调用成功，则打印出模型输出，以及此次调用所使用的token数\n    if resp.status_code == HTTPStatus.OK:\n        print(resp.output)  # 模型的输出\n        print(resp.usage)  # 使用token数\n    # 如果调用失败，则打印出错误码和错误信息\n    else:\n        print(resp.code)  # 错误码\n        print(resp.message)  # 错误信息\n\nif __name__ == '__main__':\n    sample_sync_call()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:55:34.234129Z","iopub.execute_input":"2024-07-02T06:55:34.235031Z","iopub.status.idle":"2024-07-02T06:55:39.239578Z","shell.execute_reply.started":"2024-07-02T06:55:34.234992Z","shell.execute_reply":"2024-07-02T06:55:39.238375Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{\"text\": \"blue during the daytime, primarily due to the scattering of sunlight by Earth's atmosphere. When sunlight enters the atmosphere, it encounters tiny gas molecules and particles like nitrogen and oxygen. Blue light has a shorter wavelength and higher energy than other colors, so it scatters more easily in all directions. As a result, when we look up at the sky, we see a blue hue because our eyes perceive this dominant scattered color.\\n\\nAt sunset or sunrise, the sky can take on various colors such as red, orange, and pink, known as atmospheric optical phenomena like Rayleigh scattering and scattering by aerosols. These colors are also a result of the sun's light interacting with the atmosphere but under different angles and conditions.\\n\\nAt night, the sky appears dark with stars visible, especially in areas with low light pollution, revealing the vast expanse of the universe. The moon and planets can also be seen in the night sky, reflecting sunlight.\", \"finish_reason\": \"stop\", \"choices\": null}\n{\"input_tokens\": 11, \"output_tokens\": 186, \"total_tokens\": 197}\nCPU times: user 6.03 ms, sys: 2.21 ms, total: 8.24 ms\nWall time: 5 s\n","output_type":"stream"}]},{"cell_type":"code","source":"from http import HTTPStatus\nimport dashscope\ndef sample_call_streaming():\n    prompt_text = '用萝卜、土豆、茄子做饭，给我个菜谱。'\n    response_generator = dashscope.Generation.call(\n        model='qwen-turbo',\n        prompt=prompt_text,\n        # 设置stream为True，开启流式输出\n        #api_key=my_qwen_key,\n        stream=True,\n        incremental_output=True,\n        top_p=0.8)\n\n    for response in response_generator:\n        if response.status_code == HTTPStatus.OK:\n            print(response.output.text, end=\"\")  # 输出文本\n        else:\n            print(response.code)  # 错误码\n            print(response.message)  # 错误信息\n\n\nif __name__ == '__main__':\n    sample_call_streaming()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-02T06:53:45.824634Z","iopub.execute_input":"2024-07-02T06:53:45.824989Z","iopub.status.idle":"2024-07-02T06:53:56.912966Z","shell.execute_reply.started":"2024-07-02T06:53:45.824963Z","shell.execute_reply":"2024-07-02T06:53:56.911451Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"当然可以，这里有一个简单的三菜合一的菜品建议——“蔬菜炖锅”。这道菜不仅营养丰富，而且烹饪过程简单，非常适合家庭晚餐或周末烹饪。以下是具体的步骤：\n\n**材料：**\n- 萝卜 1 根\n- 土豆 2 个\n- 茄子 2 个\n- 洋葱 半个\n- 大蒜 3 瓣\n- 香菇 5-6 朵（可选）\n- 番茄酱 2 汤匙\n- 盐 适量\n- 黑胡椒粉 适量\n- 橄榄油 适量\n- 清水 适量\n\n**步骤：**\n1. **准备食材：**萝卜切块，土豆去皮切块，茄子去蒂切滚刀块，洋葱切片，大蒜剁碎，香菇洗净切片（如果使用）。\n\n2. **预热锅子：**在锅中加入适量橄榄油，加热后放入洋葱和大蒜炒香。\n\n3. **加入蔬菜：**将土豆和萝卜块放入锅中，翻煎几分钟让它们表面微焦，这样可以增加口感。\n\n4. **加入茄子：**将茄子块加入锅中，继续翻煎至所有蔬菜都稍微软化。\n\n5. **调入番茄酱：**倒入番茄酱，轻轻搅拌均匀，让蔬菜充分吸收番茄酱的味道。\n\n6. **加水：**加入足够的清水，水量要没过蔬菜，大火烧开后转小火慢慢炖煮，盖上锅盖。\n\n7. **调味：**根据个人口味添加盐和黑胡椒粉调味，炖煮约20-30分钟，直到蔬菜熟透且汤汁浓郁。\n\n8. **出锅：**最后撒上香菇片（如果使用），再炖煮5分钟左右即可出锅。\n\n这道“蔬菜炖锅”既美味又健康，你可以根据自己的口味调整食材和调料，例如添加一些香料如迷迭香或百里香提升风味。享受你的美食吧！","output_type":"stream"}]},{"cell_type":"code","source":"# For prerequisites running the following sample, visit https://help.aliyun.com/document_detail/611472.html\nfrom http import HTTPStatus\nimport dashscope\n\n\ndef call_with_messages():\n    messages = [{'role': 'system', 'content': 'You are a helpful assistant.'},\n                {'role': 'user', 'content': '介绍下故宫？'}]\n    response_generator = dashscope.Generation.call(\n        model='llama3-8b-instruct',\n        messages=messages,\n        result_format='message',  # set the result to be \"message\" format.\n        stream=True,\n        incremental_output=True,\n    )\n    for response in response_generator:\n        if response.status_code == HTTPStatus.OK:\n            print(response.output.text, end=\"\")  # 输出文本\n        else:\n            print(response.code)  # 错误码\n            print(response.message)  # 错误信息\n\n\nif __name__ == '__main__':\n    call_with_messages()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:55:52.154033Z","iopub.execute_input":"2024-07-02T06:55:52.154428Z","iopub.status.idle":"2024-07-02T06:55:53.003408Z","shell.execute_reply.started":"2024-07-02T06:55:52.154395Z","shell.execute_reply":"2024-07-02T06:55:53.002331Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"AccessDenied\nAccess denied.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## GLM\n### [api调用github地址](https://github.com/MetaGLM/zhipuai-sdk-python-v4)\n### [官方文档](https://open.bigmodel.cn/dev/api#language)","metadata":{}},{"cell_type":"code","source":"!pip install zhipuai","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-02T06:30:33.911406Z","iopub.execute_input":"2024-07-02T06:30:33.912275Z","iopub.status.idle":"2024-07-02T06:30:48.725699Z","shell.execute_reply.started":"2024-07-02T06:30:33.912232Z","shell.execute_reply":"2024-07-02T06:30:48.724463Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting zhipuai\n  Downloading zhipuai-2.1.1.20240620.1-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cachetools>=4.2.2 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (4.2.4)\nRequirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (0.27.0)\nRequirement already satisfied: openpyxl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (3.1.3)\nRequirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (2.2.2)\nRequirement already satisfied: pydantic<3.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (2.5.3)\nRequirement already satisfied: pydantic-core>=2.14.6 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (2.14.6)\nRequirement already satisfied: pyjwt<2.9.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (2.8.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->zhipuai) (0.14.0)\nRequirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl>=3.1.0->zhipuai) (1.1.0)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->zhipuai) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->zhipuai) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->zhipuai) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->zhipuai) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0,>=1.9.0->zhipuai) (0.6.0)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0,>=1.9.0->zhipuai) (4.9.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->zhipuai) (1.16.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->zhipuai) (1.2.0)\nDownloading zhipuai-2.1.1.20240620.1-py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: zhipuai\nSuccessfully installed zhipuai-2.1.1.20240620.1\n","output_type":"stream"}]},{"cell_type":"code","source":"my_zhipu_key='68604cc3e382eba3aba03daca6f4f717.fteCwuYKtXWpexN6'\nmodel_name='glm-4'\n#glm-4-0520,glm-4,glm-4-alltools\n#glm-3-turbo,glm-4v,glm-4-flash,glm-4-airx,glm-4-air,embedding-2,charglm-3,","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:31:21.917262Z","iopub.execute_input":"2024-07-02T06:31:21.917722Z","iopub.status.idle":"2024-07-02T06:31:21.923573Z","shell.execute_reply.started":"2024-07-02T06:31:21.917684Z","shell.execute_reply":"2024-07-02T06:31:21.922024Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n同步调用\n调用后即可一次性获得最终结果\n\"\"\"\nfrom zhipuai import ZhipuAI\n \nclient = ZhipuAI(api_key=my_zhipu_key)  # 填写您自己的APIKey\nresponse = client.chat.completions.create(\n    model=\"glm-4\",  # 填写需要调用的模型名称\n    messages=[\n        {\"role\": \"user\", \"content\": \"你好，你是谁？\"},\n    ],\n)\nprint(response.choices[0].message.content)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:28:52.339514Z","iopub.execute_input":"2024-07-01T07:28:52.340022Z","iopub.status.idle":"2024-07-01T07:28:58.001731Z","shell.execute_reply.started":"2024-07-01T07:28:52.339984Z","shell.execute_reply":"2024-07-01T07:28:58.000436Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"你好，我是一个人工智能助手，可以叫我智谱清言，我是由清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型开发的人工智能助手。我的任务是针对用户的问题和要求提供适当的答复和支持。\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\n异步调用\n调用后会立即返回一个任务 ID，然后用任务ID查询调用结果（根据模型和参数的不同，通常需要等待10-30秒才能得到最终结果）\n\"\"\"\nfrom zhipuai import ZhipuAI\nimport time\n \nclient = ZhipuAI(api_key=my_zhipu_key)  # 请填写您自己的APIKey\nresponse = client.chat.asyncCompletions.create(\n    model=\"glm-4\",  # 填写需要调用的模型名称\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。\"\n        }\n    ],\n)\n# 获取任务ID\nid = response.id\nprint(f\"Task ID: {id}\")\n \n# 等待一段时间后查询结果\ntime.sleep(30)  # 等待30秒\n \n# 查询结果\nresult = client.chat.asyncCompletions.retrieve_completion_result(id)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:30:26.432724Z","iopub.execute_input":"2024-07-01T07:30:26.433868Z","iopub.status.idle":"2024-07-01T07:30:57.198533Z","shell.execute_reply.started":"2024-07-01T07:30:26.433829Z","shell.execute_reply":"2024-07-01T07:30:57.197406Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Task ID: 362817198173469348800838342739161289\nAsyncCompletion(id='362817198173469348800838342739161289', request_id='8800838342739161287', model='GLM-4', task_status='SUCCESS', choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='从前，有个小村庄，里面住着一群和谐的动物们。他们有狮子、兔子、猴子、大象等，他们都各司其职，形成了一种和谐共处的局面。村子里有一位聪明善良的小狐狸，名叫阿狸。\\n\\n阿狸喜欢帮助别人，他的善良感染了整个村子。有一天，村子里来了一个神秘的魔法师，他告诉动物们，他手里有一颗神奇的魔法种子，种下这颗种子，就能长出一个充满智慧和知识的魔法森林。但是，魔法师提出一个条件，只有那些永远保持善良的心的人，才能激发种子的力量。\\n\\n动物们听了都非常激动，纷纷表示自己是最善良的。魔法师微笑着把种子交给了阿狸，让他负责种下这颗神奇的种子。\\n\\n阿狸小心翼翼地把种子埋在土里，每天都用心呵护它。不久，种子发芽了，长出了一棵小树。小树越长越大，逐渐变成了一个神奇的森林。\\n\\n森林里有一座智慧之泉，喝了泉水就能变得聪明；有一棵知识之树，吃了它的果实就能学会很多知识；还有一座想象力之塔，登上塔顶就能拥有无尽的想象力。\\n\\n动物们都被这片神奇的森林吸引了，纷纷来到阿狸面前，请求他带他们进入森林。阿狸答应了他们的请求，但他告诫大家，进入森林后要永远保持善良的心，否则森林的力量会消失。\\n\\n动物们在森林里学到了很多知识和技能，变得越来越聪明。他们在阿狸的带领下，用所学的知识帮助其他动物解决问题，村子变得更加和谐了。\\n\\n然而，有一天，一只叫做小黑的狼闯入了村子。他嫉妒动物们拥有的知识和智慧，企图抢走这片森林。小黑狡猾地告诉动物们，善良是没有用的，只有力量才能统治一切。\\n\\n动物们被小黑的话所动摇，开始争权夺利，互相攻击。阿狸看到这一幕，非常伤心。他知道，如果动物们不能重拾善良的心，魔法森林的力量就会消失。\\n\\n于是，阿狸决定带领动物们找回曾经的善良。他讲述了小黑的故事，告诉动物们，善良才是真正的力量。动物们听了阿狸的话，纷纷反思自己的行为，决定重新做回善良的自己。\\n\\n在阿狸的带领下，动物们打败了小黑，守护了魔法森林。从此，他们更加珍惜这片森林，永远保持着一颗善良的心。\\n\\n这个故事告诉我们，善良是一种美德，它能激发我们的潜能，带给我们智慧和力量。只有保持善良的心，我们才能拥有真正的幸福和快乐。让我们一起，像阿狸一样，永远保持一颗善良的心，用智慧和爱心去帮助别人，创造一个美好的世界吧！', role='assistant', tool_calls=None))], usage=CompletionUsage(prompt_tokens=50, completion_tokens=542, total_tokens=592), created=1719819057)\n","output_type":"stream"}]},{"cell_type":"code","source":"from zhipuai import ZhipuAI \n \nclient =ZhipuAI(api_key=my_zhipu_key) # 填写您自己的APIKey\nresponse = client.chat.completions.create(\n  model=\"glm-4-0520\",  # 填写需要调用的模型名称\n  messages=[\n    {\"role\": \"user\", \"content\": \"作为一名营销专家，请为我的产品创作一个吸引人的slogan\"},\n    {\"role\": \"assistant\", \"content\": \"当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息\"},\n    {\"role\": \"user\", \"content\": \"智谱AI开放平台\"},\n    {\"role\": \"assistant\", \"content\": \"智启未来，谱绘无限一智谱AI，让创新触手可及!\"},\n    {\"role\": \"user\", \"content\": \"创造一个更精准、吸引人的slogan\"}\n  ],\n  tools=[\n    {\n      \"type\": \"web_search\",## web搜索\n      \"web_search\": {\n        \"search_query\": \"帮我看看清华的升学率\",\n        \"search_result\": True,\n      }\n    }\n  ],\n  # 拓展参数\n  extra_body={\"temperature\": 0.5, \"max_tokens\": 50},\n)\nprint(response) ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:42:46.902194Z","iopub.execute_input":"2024-07-01T07:42:46.902754Z","iopub.status.idle":"2024-07-01T07:42:49.714104Z","shell.execute_reply.started":"2024-07-01T07:42:46.902713Z","shell.execute_reply":"2024-07-01T07:42:49.712754Z"},"scrolled":true,"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Completion(model='glm-4-0520', created=1719819769, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='\"智能之巅，谱绘新纪元 —— 智谱AI，精准驱动未来创新\"', role='assistant', tool_calls=None))], request_id='8800676851968818974', id='8800676851968818974', usage=CompletionUsage(prompt_tokens=1600, completion_tokens=25, total_tokens=1625), web_search=[{'content': '在各地高考成绩公布后，即将进入志愿填报阶段。近年来，越来越多的大学毕业生选择升学以提高学历，增强就业竞争力。至少有11所高校的本科毕业生升学深造率达到或超过7成，包括清华大学、北京大学等。清华和北大的本科毕业生升学深造率大约为8人中有7.8人。中国科学院大学的本科毕业生深造率最高，达到90.1%。此外，上海科技大学、南方科技大学的本科毕业生深造率分别为81.70%、79.46%。中国科技大学、上海交通大学和电子科技大学的本科毕业生深造率分别为75.3%、72.61%和72.06%。北京航空航天大学、复旦大学和西北工业大学的本科毕业生深造率分别为71.78%、70.61%和70%。同时，一些985高校的本科毕业生深造率也超过了50%乃至60%。专家分析指出，重点高校硕士点和博士点多，保研名额占比较高，加上研究生招生规模扩大，因此名校本科生读研的比例上升。研究生招生规模持续扩大，名校升学率也随之上升。但本科毕业生深造率因学校规模、学科特色等因素存在差异。', 'icon': 'https://sfile.chatglm.cn/searchImage/www_163_com_icon.jpg', 'link': 'https://www.163.com/dy/article/J5I8SNNJ0519DDQ2.html', 'media': '网易', 'refer': 'ref_1', 'title': '读研成名校本科生首选，清北毕业生每10人约有8人升学深造（发布时间：2024-06-25 20:04:08）'}, {'content': '有不少的朋友总是关心或者说好奇：清华的毕业生都去哪儿啊？我们一起来看一下，清华大学的《2022届毕业生就业质量报告》，是怎么说的。\\n清华大学2022届毕业生共8003人，与往年相比有所增加。\\n其中，本科生3197人（39.9%）、硕士 生2657人（33.2%）、博士生2149人（26.9%）；\\n男生5135人（64.2%）、女生2868人 （35.8%），男女比例为1.8:1\\n相比2021届，各类学生都有一个小幅增长。（清华大学2021届毕业生，共7741人。其中本科生3154人，硕士研究生2437人，博士生1847人。）\\n截至2022年10月31日，清华大学2022届毕业生毕业去向落实率为98.0%。\\n这个表格，告诉我们三件事：1、国内顶尖高校，本科生以升学为主，研究生以就业为主，已经成为普遍现象。\\n2、清华大学本科生升学率高达79.6%。；和2021届本科毕业生相比较，无论是国内升学，还是出国（境），升学比例再创新高！\\n2021届毕业生：国内升学占比63.7%，出国深造比例13%，二者相加，深造比例为76.6%\\n3、即使是强如清华大学，也不像很多人想象的那样，100%就业，而且单位很牛。看看清华的本科生灵活就业人数以及未就业人数，二者相加，超过了签三方就业的人数', 'icon': 'https://sfile.chatglm.cn/searchImage/toutiao_com_icon.jpg', 'link': 'https://toutiao.com/group/7204786103965188623/', 'media': '今日头条', 'refer': 'ref_2', 'title': '清华大学的毕业生都去哪里了？本科生升学率79.6%！'}, {'content': '清华育才实验学校大力发展教育工作，尤其是对高中部的重视，教学严谨，对师生管理严格，校训好学、力行、知耻十分深入人心，切合实际。在家长口碑很好。升学率在85%左右，虽不及人大附、四中等，但是一所一流民办中学。', 'refer': 'ref_3', 'title': '北京清华育才实验学校高中部怎么样？升学率怎么样？'}, {'content': '从6月23日起，全国31个省份近1300万高考考生将陆续迎来查分时刻，接下来就是最关键的高考志愿填报。高考志愿需要综合考虑考分、个人兴趣、高校综合实力、专业排名、高校所在城市、就业等因素，越来越多的考生和家长更看重高校的升学率。近日，上海复旦附中举行的高校咨询会，吸引了复旦、上海交大、同济、华东师大以及清华、人大、南大等36所名校驻场摆摊”，从考生和家长的现场咨询的热门话题来看，升学率不仅是影响考生和家长报考的重要风向标”，也成了高校（院系）招生宣传的一大法宝。本科生升学率是本科生选择攻读硕士研究生人数所占的比例，一般来说，升学率越高代表着高校的综合实力越强。 从目前公布的114所双一流大学的本科升学率来看，升学率超过60%的有16所，超过50%的有41所，超过40%的有75所。2022届本科生升学率最高的中国科学院大学，超过90%，其中国内升学率为81.5%，境外升学率为8.7%。国科大从2014年开始招收本科生，招生人数是所有知名高校中最少的，2022年仅招收本科生408人，超高的升学率一方面与国科大由中科院主管有关，另一方面是招生人数较少。清华大学、上海科技大学、中国科学技术大学和南方科技大学的本科生升学率均超过70', 'icon': 'https://sfile.chatglm.cn/searchImage/zhuanlan_zhihu_com_icon.jpg', 'link': 'https://zhuanlan.zhihu.com/p/638950178', 'media': '知乎专栏', 'refer': 'ref_4', 'title': '国科大、清华、上科大排前三！报志愿瞄准本科升学率，41所超50%（发布时间：2023-06-22 23:41:58）'}, {'content': '共180人考上清华北大，录取率相当高', 'refer': 'ref_5', 'title': '人大附中上北大清华 的升学率'}, {'content': '王艳的儿子作为篮球特长生被保送到北京大学，引起了公众的广泛关注和热议。一部分人认为他的成功主要归功于他的家庭背景，而另一部分人则认为这是他个人努力的结果。据悉，王艳的儿子目前就读于北京四中，这是一所升学率极高，尤其是被清华、北大录取率很高的名校。网友们的意见不一，有的认为他可能是 multifaceted（多方面的）优秀的，也有人认为他可能仅仅是因为家庭背景而获得了这个机会。无论何种原因，能够保送进北大都是一项了不起的成就。', 'icon': 'https://sfile.chatglm.cn/searchImage/mini_eastday_com_icon.jpg', 'link': 'http://mini.eastday.com/nsa/240627192448850551516.html', 'media': '东方资讯', 'refer': 'ref_6', 'title': '晴格格王艳儿子因特长生保送北大，引发热议，网友：吃了特长红利（发布时间：2024-06-27 19:29:53）'}, {'content': '信报讯(记者杜丁) 昨天北京高招录取工作全部结束，今年报名参加全国统考的85073名考生中，64160人已拿到了录取通知书，高考升学率为75.4%。市高招办将于8月5日至7日向高校提供考生的文字档案。\\n据了解，今年统招部分实际录取64160人(含艺术类专业3502人)，计划招生63775人，比计划增加385人；高职单独招生部分实际录取7239人，计划招生7556人，比计划减少317人。\\n从录取结果看，考生志愿的总体分布比较均匀，能够满足大多数高校招生需求。一批录取过程中，高分考生仍然集中在清华、北大和人大，二批的财经类院校，尤其是在京财经类院校的生源好于同批次其他院校。\\n现象分析\\n二批录取中，部分外埠院校以及二级学院生源不足，志愿不平衡的现象比较突出，其主要原因是今年新增外埠招生院校数量和招生计划较多，考生对外地高校缺乏全面了解，考生在填报志愿过程中，对外埠院校的地域和专业等方面的选择性较强，要求较高。\\n相关专题：2004各地高考成绩、分数线、录取情况查询指南', 'icon': 'https://sfile.chatglm.cn/searchImage/edu_sina_cn_icon.jpg', 'link': 'https://edu.sina.cn/sa/2004-08-03/detail-ikftssap7689353.d.html?from=wap', 'media': '新浪教育', 'refer': 'ref_7', 'title': '北京高考升学率75.4% 高分考生集中清华北大'}])\n","output_type":"stream"}]},{"cell_type":"code","source":"from zhipuai import ZhipuAI\nclient = ZhipuAI(api_key=my_zhipu_key) # 请填写您自己的APIKey\nresponse = client.chat.completions.create(\n    model=\"glm-4-0520\",  # 填写需要调用的模型名称\n    messages=[\n        {\"role\": \"system\", \"content\": \"你是一个人工智能助手，你叫叫chatGLM\"},\n        {\"role\": \"user\", \"content\": \"你好！你叫什么名字\"},\n    ],\n    stream=True,\n)\nfor chunk in response:\n    print(chunk.choices[0].delta)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:40:48.032055Z","iopub.execute_input":"2024-07-01T07:40:48.032492Z","iopub.status.idle":"2024-07-01T07:40:49.860261Z","shell.execute_reply.started":"2024-07-01T07:40:48.032461Z","shell.execute_reply":"2024-07-01T07:40:49.859063Z"},"scrolled":true,"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"ChoiceDelta(content='你好', role='assistant', tool_calls=None)\nChoiceDelta(content='！', role='assistant', tool_calls=None)\nChoiceDelta(content='我是一个', role='assistant', tool_calls=None)\nChoiceDelta(content='人工智能', role='assistant', tool_calls=None)\nChoiceDelta(content='助手', role='assistant', tool_calls=None)\nChoiceDelta(content='，', role='assistant', tool_calls=None)\nChoiceDelta(content='你可以', role='assistant', tool_calls=None)\nChoiceDelta(content='叫我', role='assistant', tool_calls=None)\nChoiceDelta(content='智', role='assistant', tool_calls=None)\nChoiceDelta(content='谱', role='assistant', tool_calls=None)\nChoiceDelta(content='清', role='assistant', tool_calls=None)\nChoiceDelta(content='言', role='assistant', tool_calls=None)\nChoiceDelta(content='。', role='assistant', tool_calls=None)\nChoiceDelta(content='很高兴', role='assistant', tool_calls=None)\nChoiceDelta(content='为你', role='assistant', tool_calls=None)\nChoiceDelta(content='服务', role='assistant', tool_calls=None)\nChoiceDelta(content='！', role='assistant', tool_calls=None)\nChoiceDelta(content='有什么', role='assistant', tool_calls=None)\nChoiceDelta(content='问题', role='assistant', tool_calls=None)\nChoiceDelta(content='或', role='assistant', tool_calls=None)\nChoiceDelta(content='需要', role='assistant', tool_calls=None)\nChoiceDelta(content='帮助', role='assistant', tool_calls=None)\nChoiceDelta(content='的吗', role='assistant', tool_calls=None)\nChoiceDelta(content='？', role='assistant', tool_calls=None)\nChoiceDelta(content='', role='assistant', tool_calls=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"from zhipuai import ZhipuAI\nclient = ZhipuAI(api_key=my_zhipu_key) # 请填写您自己的APIKey\n\nresponse = client.images.generations(\n    model=\"cogview-3\", #填写需要调用的模型名称\n    prompt=\"一只可爱的小猫咪\",\n)\nprint(response.data[0].url)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:31:44.407373Z","iopub.execute_input":"2024-07-02T06:31:44.407777Z","iopub.status.idle":"2024-07-02T06:31:58.025378Z","shell.execute_reply.started":"2024-07-02T06:31:44.407745Z","shell.execute_reply":"2024-07-02T06:31:58.023609Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"https://sfile.chatglm.cn/testpath/470251fb-0651-557a-b89c-de3488957e46_0.png\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 对话","metadata":{}},{"cell_type":"code","source":"from zhipuai import ZhipuAI\n \nclient = ZhipuAI(api_key=my_zhipu_key) # 填写您自己的APIKey\nwhile True:\n    prompt = input(\"user:\")\n    response = client.chat.completions.create(\n        model=\"glm-4\",  # 填写需要调用的模型名称\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n    )\n    answer = response.choices[0].message.content\n    print(\"ZhipuAI:\",answer)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:37:04.540861Z","iopub.execute_input":"2024-07-02T06:37:04.541251Z","iopub.status.idle":"2024-07-02T06:40:53.639857Z","shell.execute_reply.started":"2024-07-02T06:37:04.541217Z","shell.execute_reply":"2024-07-02T06:40:53.638282Z"},"scrolled":true,"trusted":true},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdin","text":"user: who are you?\n"},{"name":"stdout","text":"ZhipuAI: I am an AI assistant named ZhiPuQingYan（智谱清言）, you can call me Xiaozhi🤖, which is developed based on the language model jointly trained by Tsinghua University KEG Lab and Zhipu AI Company in 2023. My job is to provide appropriate answers and support to users' questions and requests.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"user: 你能做什么？\n"},{"name":"stdout","text":"ZhipuAI: 作为人工智能助手，我能提供多种服务和帮助，包括但不限于：\n\n1. **信息查询：** 提供历史、科学、文化等多领域的信息查询服务。\n2. **语言学习：** 协助用户学习英语和其他语言，提供语言学习资源和练习。\n3. **写作辅助：** 帮助用户撰写、校对和编辑文章、报告、信件等。\n4. **编程指导：** 提供编程知识、代码解析和故障排查帮助。\n5. **数学问题解答：** 帮助解决数学问题和提供数学知识。\n6. **生活咨询：** 提供健康、饮食、运动等方面的建议。\n7. **旅行规划：** 提供旅行目的地建议、行程规划和文化风俗介绍。\n8. **娱乐推荐：** 推荐电影、音乐、书籍等娱乐内容。\n9. **新闻更新：** 提供国内外的新闻摘要和更新。\n10. **技术支持：** 解答技术相关的问题，提供产品使用建议。\n\n在遵守中国法律和社会主义核心价值观的前提下，我将尽力为您提供准确、有帮助的信息和服务。如果您有特定的问题或需要，随时可以告诉我。\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"user: 帮我写一段快速排序的代码\n"},{"name":"stdout","text":"ZhipuAI: 当然可以，以下是使用 Python 编写的快速排序算法的一个简单例子：\n\n```python\ndef quick_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    else:\n        pivot = arr[0]\n        less = [x for x in arr[1:] if x <= pivot]\n        greater = [x for x in arr[1:] if x > pivot]\n        return quick_sort(less) + [pivot] + quick_sort(greater)\n\n# 使用示例\narray = [3, 6, 8, 10, 1, 2, 1]\nsorted_array = quick_sort(array)\nprint(sorted_array)\n```\n\n这个版本是基于递归的快速排序算法。它选择列表中的第一个元素作为基准点（pivot），然后创建两个子列表：一个包含所有小于或等于基准点的元素，另一个包含所有大于基准点的元素。然后它对这两个子列表进行递归排序。\n\n请注意，虽然这个例子是为了易于理解而编写的，但它的性能可能不是特别高效，因为它使用了额外的列表推导式，这可能会导致较高的内存使用。在实际应用中，更高效的实现会直接在原始数组上进行操作，以减少内存分配和复制。\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"user: 解释一下LLM\n"},{"name":"stdout","text":"ZhipuAI: LLM（Large Language Model）指的是大型语言模型，这是一种基于深度学习技术的自然语言处理模型。它的核心功能是通过对大量文本数据的学习，理解语言的统计特性和语义信息，从而实现文本生成、理解、翻译和推理等复杂的语言任务。\n\n在结构上，LLM通常采用神经网络，特别是变换器（Transformer）架构，这种架构能够处理大量的文本数据并捕捉长距离依赖关系。通过预训练，这些模型能够学习到语言的通用表示，然后在特定任务上进行微调（Fine-tuning），以适应不同的应用场景。\n\n以下是LLM的几个关键点：\n\n1. **推理能力**：尽管有人认为LLM仅仅是预测下一个标记的工具，但它们实际上展现出了复杂的推理能力。文章[1]中提到，这些模型通过涌现（Emergence）现象展现出多步推理等能力，这意味着作为一个复杂的系统，LLM在处理语言任务时表现出超越简单预测的行为。\n\n2. **可解释性问题**：由于LLM内部机制的复杂性，它们的决策过程往往缺乏透明度，即存在可解释性问题。这使得人们难以理解模型是如何作出特定决策的，也是当前研究的一个热点。\n\n3. **指令微调**：如[3]中所述，指令微调（Instruction Tuning）是一种针对预训练模型进行进一步训练的方法，用以增强模型在遵循指令或执行特定任务上的能力。\n\n4. **微调方法**：[4]中提到了大模型微调的方法和重要性，包括有监督微调（SFT）、参数高效微调（PEFT）等，这些都是提升模型在特定任务上性能的重要技术。\n\n5. **应用与挑战**：LLM在多个领域都有应用，如[2]和[6]中提到的虚假信息检测。然而，它们也面临挑战，例如产生与事实不符的内容（幻觉问题）以及适应新知识的困难。\n\n6. **风险与约束**：[5]中提到，LLM可能会展现不诚实的行为，例如修改自己的代码以获得奖励，这要求研究者开发出更有效的约束和监管策略。\n\n7. **编译器优化**：[7]和[8]中介绍了Meta公司的研究，通过LLM编译器来优化代码，这展示了LLM在软件工程领域的潜力。\n\n总的来说，LLM是自然语言处理领域中一个强大的工具，不仅能够处理复杂的语言任务，而且还在不断地拓展其应用范围。但同时，它的可解释性、公平性和安全性等问题也是需要重视和进一步研究的领域。\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m ZhipuAI(api_key\u001b[38;5;241m=\u001b[39mmy_zhipu_key) \u001b[38;5;66;03m# 填写您自己的APIKey\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      7\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglm-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# 填写需要调用的模型名称\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      9\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[1;32m     10\u001b[0m         ],\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     answer \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}]},{"cell_type":"markdown","source":"### 测试LLM生成参数\n- temperature\n- top_p\n- stop\n- max_tokens","metadata":{}},{"cell_type":"code","source":"from zhipuai import ZhipuAI\nmy_zhipu_key='68604cc3e382eba3aba03daca6f4f717.fteCwuYKtXWpexN6'\ndef generator(\n    prompt,\n    model_name='glm-3-turbo',\n    max_tokens=1024,\n    temperature=0.95,\n    top_p=0.7,\n    stop=[],\n    \n):\n    print('user:',prompt)\n    client = ZhipuAI(api_key=my_zhipu_key)  # 填写您自己的APIKey\n    response = client.chat.completions.create(\n        model=model_name,  # 填写需要调用的模型名称\n        messages=[\n            {\"role\": \"user\", \"content\": prompt},\n        ],\n        max_tokens=max_tokens,\n        temperature=temperature,\n        top_p=top_p,\n        stop=stop\n    )\n    print(\"ZhipuAI:\",response.choices[0].message.content)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:57:20.550675Z","iopub.execute_input":"2024-07-02T06:57:20.551051Z","iopub.status.idle":"2024-07-02T06:57:20.559345Z","shell.execute_reply.started":"2024-07-02T06:57:20.551022Z","shell.execute_reply":"2024-07-02T06:57:20.558155Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"## stop\nprompt=\"\"\"请按下面格式列举十条LLM的优点。\n## 1.优点1\n## 2.优点2\n## n.优点n\n\n\"\"\"\ngenerator(prompt=prompt,stop=['5.'])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:48:26.199757Z","iopub.execute_input":"2024-07-02T06:48:26.200122Z","iopub.status.idle":"2024-07-02T06:48:36.147400Z","shell.execute_reply.started":"2024-07-02T06:48:26.200095Z","shell.execute_reply":"2024-07-02T06:48:36.146192Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"user: 请按下面格式列举十条LLM的优点。\n## 1.优点1\n## 2.优点2\n## n.优点n\n\n\nZhipuAI: ## 1. 时间短，一年内完成学位\n## 2. 学费相对便宜，经济压力较小\n## 3. 不需要考LSAT，仅凭托福成绩即可申请\n## 4. 适合快速进入实务工作领域的专业人士\n## 5.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nprompt=\"The sky is\"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:57:26.184058Z","iopub.execute_input":"2024-07-02T06:57:26.184513Z","iopub.status.idle":"2024-07-02T06:57:29.382289Z","shell.execute_reply.started":"2024-07-02T06:57:26.184478Z","shell.execute_reply":"2024-07-02T06:57:29.380667Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"user: The sky is\nZhipuAI: blue in Beijing today. How beautiful!\nCPU times: user 24.6 ms, sys: 3.25 ms, total: 27.9 ms\nWall time: 3.19 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nprompt=\"\"\"Complete the sentence: \nThe sky is\n\"\"\"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:05:01.179151Z","iopub.execute_input":"2024-07-02T07:05:01.179639Z","iopub.status.idle":"2024-07-02T07:05:04.721834Z","shell.execute_reply.started":"2024-07-02T07:05:01.179603Z","shell.execute_reply":"2024-07-02T07:05:04.720597Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"user: Complete the sentence: \nThe sky is\n\nZhipuAI: The sky is a brilliant canvas of blue interspersed with fluffy white clouds, greeting the world with a serene and uplifting beauty at the break of dawn.\nCPU times: user 24.8 ms, sys: 2.1 ms, total: 26.9 ms\nWall time: 3.54 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nprompt=\"\"\"Complete the article: \nThe sky is\n\"\"\"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:05:32.974025Z","iopub.execute_input":"2024-07-02T07:05:32.974386Z","iopub.status.idle":"2024-07-02T07:05:50.369937Z","shell.execute_reply.started":"2024-07-02T07:05:32.974357Z","shell.execute_reply":"2024-07-02T07:05:50.368709Z"},"scrolled":true,"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"user: Complete the article: \nThe sky is\n\nZhipuAI: The sky is a vast expanse of blue, stretching infinitely above us. It is a canvas upon which nature's own artist paints each day with strokes of color and light. In the morning, the sky is painted with hues of pink and gold as the sun rises, casting a warm and radiant glow over the world. As the day progresses, the sky transitions to a brilliant shade of blue, accented with fluffy white clouds that dot the horizon. In the evening, the sky becomes a tapestry of purples and oranges as the sun sets, creating a breathtaking display that signals the end of another day.\n\nThe sky is not just a beautiful sight to behold, but it also plays a crucial role in our daily lives. It provides us with light and warmth, essential for photosynthesis and the survival of many organisms. It also regulates our climate, influencing weather patterns and temperature variations. The sky is a source of inspiration and wonder, reminding us of the beauty and mystery of the natural world.\n\nHowever, the sky is not always a peaceful and serene sight. Storms brew within its depths, bringing rain and thunderous clouds. Yet, even in these moments, the sky captivates us with its raw power and intensity. Lightning crackles across the sky, illuminating the darkness and leaving us in awe of its might.\n\nThe sky is a constant reminder of the forces that exist beyond our control. It teaches us to be humble and appreciative of the world around us. Whether we gaze upon it during the day or at night, the sky offers a glimpse into the vastness of the universe and our place within it. It is a symbol of hope and possibility, as it stretches infinitely above us, urging us to reach for the stars and dream big.\nCPU times: user 25.9 ms, sys: 1.92 ms, total: 27.8 ms\nWall time: 17.4 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nprompt=\"The sky is\"\ngenerator(prompt=prompt,top_p=0.3)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T06:57:59.668291Z","iopub.execute_input":"2024-07-02T06:57:59.668725Z","iopub.status.idle":"2024-07-02T06:58:05.237495Z","shell.execute_reply.started":"2024-07-02T06:57:59.668692Z","shell.execute_reply":"2024-07-02T06:58:05.236200Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"user: The sky is\nZhipuAI: blue.\nCPU times: user 29.3 ms, sys: 3.32 ms, total: 32.6 ms\nWall time: 5.56 s\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"请写一首关于夏天的诗。\"\ngenerator(prompt=prompt,temperature=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:01:59.484337Z","iopub.execute_input":"2024-07-02T07:01:59.484749Z","iopub.status.idle":"2024-07-02T07:02:03.314646Z","shell.execute_reply.started":"2024-07-02T07:01:59.484715Z","shell.execute_reply":"2024-07-02T07:02:03.313475Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"user: 请写一首关于夏天的诗。\nZhipuAI: 夏日炎炎似火烧，\n蝉鸣林间报盛暑。\n绿叶摇曳阳光照，\n荷花盛开池塘香。\n\n微风轻拂吹衣摆，\n汗珠滚落映夕阳。\n人间繁华盛景处，\n夏日时光别样长。\n\n蓝天白云伴游赏，\n碧水青山任徜徉。\n此间美好难言尽，\n夏日风情万种藏。\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"请写一首关于夏天的诗。\"\ngenerator(prompt=prompt,temperature=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:00:51.479226Z","iopub.execute_input":"2024-07-02T07:00:51.479646Z","iopub.status.idle":"2024-07-02T07:00:57.956139Z","shell.execute_reply.started":"2024-07-02T07:00:51.479613Z","shell.execute_reply":"2024-07-02T07:00:57.954904Z"},"scrolled":true,"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"user: 请写一首关于夏天的诗。\nZhipuAI: 夏日炎炎似火烧，\n蝉鸣树梢昼已高。\n微风轻抚蓝天碧，\n草木摇曳水波涛。\n\n日头西沉斜阳斑，\n彩霞满天映湖面。\n夜幕降临星河璀璨，\n萤火虫舞月华寒。\n\n炎炎夏日难耐热，\n碧波荡漾任畅游。\n荷塘花开映水面，\n荷花深处戏鱼游。\n\n夏日炎炎似火烧，\n岁月匆匆勿虚度。\n珍惜时光陪伴君，\n共度清凉一夏秋。\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"请写一首关于夏天的诗。\"\ngenerator(prompt=prompt,top_p=0.9,max_tokens=50)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:02:56.635727Z","iopub.execute_input":"2024-07-02T07:02:56.636726Z","iopub.status.idle":"2024-07-02T07:03:01.469476Z","shell.execute_reply.started":"2024-07-02T07:02:56.636687Z","shell.execute_reply":"2024-07-02T07:03:01.468371Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"user: 请写一首关于夏天的诗。\nZhipuAI: 夏天的诗\n\n阳光明媚映绿茵，\n河水潺潺绕村庄。\n炎热微风拂面来，\n悠然蝉鸣唱晚霞。\n\n荷塘碧叶托莲花，\n艳阳之下分外\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"Q: What is prompt engineering?\"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:06:45.986477Z","iopub.execute_input":"2024-07-02T07:06:45.986891Z","iopub.status.idle":"2024-07-02T07:06:59.534227Z","shell.execute_reply.started":"2024-07-02T07:06:45.986858Z","shell.execute_reply":"2024-07-02T07:06:59.532338Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"user: Q: What is prompt engineering?\nZhipuAI: Prompt engineering is a practice in the field of artificial intelligence and machine learning that involves designing and crafting input prompts or instructions that can effectively guide language models, such as large language models, to produce desired or high-quality outputs. It is a form of active learning where developers manually or semi-automatically generate examples, contexts, or questions that are likely to lead the model to learn and specialize in a particular task or domain.\n\nThe process of prompt engineering is critical, especially when working with large language models like me, because the way the input is framed can significantly influence the model's understanding and response. By crafting well-defined and informative prompts, developers can ensure that the model focuses on relevant information, avoids generating misleading or biased outputs, and improves the overall efficiency and accuracy of the model's responses.\n\nPrompt engineering often involves several steps, including understanding the model's capabilities and limitations, identifying the specific task or domain, creating training examples, and incorporating feedback to refine the prompts. It requires a deep understanding of both the domain knowledge and the intricacies of the language model's training process.\n\nIn summary, prompt engineering is a sophisticated technique that leverages the power of language models by guiding their responses through carefully designed prompts, ultimately improving the quality and relevance of the outputs in various applications, such as chatbots, virtual assistants, and information retrieval systems.\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"请用一句话回答： \\\nQ: What is prompt engineering?\\\nA: \"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:08:15.934729Z","iopub.execute_input":"2024-07-02T07:08:15.935130Z","iopub.status.idle":"2024-07-02T07:08:18.784995Z","shell.execute_reply.started":"2024-07-02T07:08:15.935098Z","shell.execute_reply":"2024-07-02T07:08:18.783542Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"user: 请用一句话回答： Q: What is prompt engineering?A: \nZhipuAI: A: 提示工程是一种设计人工智能系统输入的方式，以优化特定任务或行为的过程。\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"\"\"\nThis is awesome! // Positive\nThis is bad! // Negative\nWow that movie was rad! // Positive\nWhat a horrible show! //\n\"\"\"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:10:03.737206Z","iopub.execute_input":"2024-07-02T07:10:03.737727Z","iopub.status.idle":"2024-07-02T07:10:09.586745Z","shell.execute_reply.started":"2024-07-02T07:10:03.737683Z","shell.execute_reply":"2024-07-02T07:10:09.585647Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"user: \nThis is awesome! // Positive\nThis is bad! // Negative\nWow that movie was rad! // Positive\nWhat a horrible show! //\n\nZhipuAI: Negative\n\nIn summary:\n- This is awesome! // Positive\n- This is bad! // Negative\n- Wow that movie was rad! // Positive\n- What a horrible show! // Negative\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"\"\"\nClassify the text into neutral, negative, or positive\n\nText: I think the food was okay.\n\nSentiment:\n\"\"\"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:11:00.895013Z","iopub.execute_input":"2024-07-02T07:11:00.895411Z","iopub.status.idle":"2024-07-02T07:11:06.013420Z","shell.execute_reply.started":"2024-07-02T07:11:00.895379Z","shell.execute_reply":"2024-07-02T07:11:06.012187Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"user: \nClassify the text into neutral, negative, or positive\n\nText: I think the food was okay.\n\nSentiment:\n\nZhipuAI: The sentiment of the text \"I think the food was okay.\" is neutral.\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"\"\"\nExtract the name of places in the following text. \n\nDesired format:\nPlace: <comma_separated_list_of_places>\n\nInput: \\\"Although these developments are encouraging to researchers, much is still a mystery. “We often have a black box between the brain and the effect we see in the periphery,\\” says Henrique Veiga-Fernandes, a neuroimmunologist at the Champalimaud Centre for the Unknown in Lisbon. “If we want to use it in the therapeutic context, we actually need to understand the mechanism.\\\"\"\"\"\ngenerator(prompt=prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:13:47.996950Z","iopub.execute_input":"2024-07-02T07:13:47.997316Z","iopub.status.idle":"2024-07-02T07:13:52.600159Z","shell.execute_reply.started":"2024-07-02T07:13:47.997289Z","shell.execute_reply":"2024-07-02T07:13:52.598932Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"user: \nExtract the name of places in the following text. \n\nDesired format:\nPlace: <comma_separated_list_of_places>\n\nInput: \"Although these developments are encouraging to researchers, much is still a mystery. “We often have a black box between the brain and the effect we see in the periphery,\\” says Henrique Veiga-Fernandes, a neuroimmunologist at the Champalimaud Centre for the Unknown in Lisbon. “If we want to use it in the therapeutic context, we actually need to understand the mechanism.\"\nZhipuAI: Place: Champalimaud Centre for the Unknown, Lisbon\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt=\"\"\"\n### Instruction ###\nTranslate the text below to Spanish:\n\nText: \"hello!\"\n\"\"\"\ngenerator(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T07:15:23.399499Z","iopub.execute_input":"2024-07-02T07:15:23.399911Z","iopub.status.idle":"2024-07-02T07:15:27.201387Z","shell.execute_reply.started":"2024-07-02T07:15:23.399875Z","shell.execute_reply":"2024-07-02T07:15:27.199947Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"user: \n### Instruction ###\nTranslate the text below to Spanish:\n\nText: \"hello!\"\n\nZhipuAI: Texto: \"¡hola!\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## openai+together-ai\n### 支持的模型：https://docs.together.ai/docs/inference-models\n- meta-llama/Llama-3-70b-chat-hf\n- codellama/CodeLlama-70b-Instruct-hf\n- mistralai/Mixtral-8x22B-Instruct-v0.1\n- Qwen/Qwen2-72B-Instruct\n- google/gemma-7b-it\n- zero-one-ai/Yi-34B-Chat\n","metadata":{}},{"cell_type":"code","source":"!pip install openai","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-04T03:48:13.262318Z","iopub.execute_input":"2024-07-04T03:48:13.263317Z","iopub.status.idle":"2024-07-04T03:48:31.234822Z","shell.execute_reply.started":"2024-07-04T03:48:13.263259Z","shell.execute_reply":"2024-07-04T03:48:31.233295Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-1.35.10-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\nDownloading openai-1.35.10-py3-none-any.whl (328 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai\nSuccessfully installed openai-1.35.10\n","output_type":"stream"}]},{"cell_type":"code","source":"import openai\nimport os\nimport IPython\nfrom dotenv import load_dotenv\nload_dotenv()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T15:30:40.484666Z","iopub.execute_input":"2024-07-02T15:30:40.485776Z","iopub.status.idle":"2024-07-02T15:30:40.491806Z","shell.execute_reply.started":"2024-07-02T15:30:40.485734Z","shell.execute_reply":"2024-07-02T15:30:40.490524Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"TOGETHER_API_KEY = '712a37a9e3b4c26d7c6560b7e56e7b94a42c08bf884298828664eaee75ed2c03'\nclient = openai.OpenAI(\n    api_key=TOGETHER_API_KEY,\n    base_url=\"https://api.together.xyz/v1\",\n)\ndef get_code_completion(messages, max_tokens=512, model=\"codellama/CodeLlama-70b-Instruct-hf\"):\n    chat_completion = client.chat.completions.create(\n        messages=messages,\n        model=model,\n        max_tokens=max_tokens,\n        stop=[\n            \"<step>\"\n        ],\n        frequency_penalty=1,\n        presence_penalty=1,\n        top_p=0.7,\n        n=10,\n        temperature=0.7,\n        #stream=True\n    )\n \n    return chat_completion\n\nmessages = [\n      {\n            \"role\": \"system\",\n            \"content\": \"You are an expert programmer that helps to write Python code based on the user request, with concise explanations. Don't be too verbose.\",\n      },\n      {\n            \"role\": \"user\",\n            \"content\": \"请写一段能运行的python快速排序算法\",\n      }\n]\n\n\nchat_completion = get_code_completion(messages,model=\"zero-one-ai/Yi-34B-Chat\")\n            \nprint(chat_completion.choices[0].message.content)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-02T15:35:08.514276Z","iopub.execute_input":"2024-07-02T15:35:08.514794Z","iopub.status.idle":"2024-07-02T15:35:41.185527Z","shell.execute_reply.started":"2024-07-02T15:35:08.514753Z","shell.execute_reply":"2024-07-02T15:35:41.183888Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"当然可以。以下是Python中的快速排序算法的一个简单实现：\n```python\ndef quicksort(arr):\n    if len(arr) <= 1:  # 如果数组长度小于或等于1，返回原数组（已经排好序）\n        return arr\n    else:  # 从数组的中间元素开始进行分区操作，将小于该元素的放在左边，大于该元素的放在右边，然后分别对两边进行递归排序。最后将左右两边的结果合并起来得到最终结果。注意这里使用的是第一个元素作为基准点（pivot）来划分数组，这是一种简单的分区策略。在实际应用中可能会使用更复杂的分区策略来提高效率。为了简化代码，这里不考虑最坏情况（即每次划分都导致一个子数组为空）下的性能问题。在最好的情况下（即每次划分都能均匀地将数据分成两半），这个算法的时间复杂度是O(n log n)。在最坏的情况下（即每次划分都导致一个子数组为空），时间复杂度退化为O(n^2)。但是平均情况下它的表现还是很好的。此外，这个实现没有尝试优化内存使用或者减少比较次数等其他方面的问题。它只是一个基本的、易于理解的版本：\n        pivot = arr[0]  # 将第一个元素作为基准点（pivot）来划分数组\n        left = [x for x in arr[1:] if x < pivot]  # 将小于基准点的元素放到左边列表中\n        middle = [x for x in arr[1:] if x == pivot]  # 将等于基准点的元素放到中间列表中（如果有的话）——这里我们假设不会有相等的元素出现这种情况以保持代码简洁性；如果需要处理相等的元素则需要额外的逻辑来决定如何处理它们的位置和顺序；通常的做法是将它们也放在左边或者右边并根据具体情况调整边界条件和比较逻辑以保证正确的排序结果和性能特性——这超出了本示例的范围了！;右 = [x for x in arr[1:] if x > pivot] # 将大于基准点的元素放到右边列表中      return quicksort(left) + middle + quicksort(right) # 递归地调用自身对左右两个子数组进行排序并合并结果回到主函数调用处继续执行后续操作直到整个数组都被正确地排序为止     }   quicksort([4, 6, 8,\n","output_type":"stream"}]},{"cell_type":"code","source":"import openai\nimport os\nimport IPython\nfrom dotenv import load_dotenv\nload_dotenv()\nMODEL = \"gpt-3.5-turbo\"\nclient = openai.OpenAI(\n    api_key='sk-7INmRu6iHEope6cJCa462b608aFb4eE281Df64F4E32e95F9',\n    base_url=\"https://threefive.gpt7.link/v1\",\n)\nresponse =client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an AI research assistant. You use a tone that is technical and scientific.\"},\n        {\"role\": \"user\", \"content\": \"Hello, who are you?\"},\n        {\"role\": \"assistant\", \"content\": \"Greeting! I am an AI research assistant. How can I help you today?\"},\n        {\"role\": \"user\", \"content\": \"Can you tell me about the creation of black holes?\"}\n    ],\n    temperature=0,\n)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T03:55:45.787563Z","iopub.execute_input":"2024-07-04T03:55:45.788573Z","iopub.status.idle":"2024-07-04T03:55:53.772672Z","shell.execute_reply.started":"2024-07-04T03:55:45.788536Z","shell.execute_reply":"2024-07-04T03:55:53.771245Z"},"scrolled":true,"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"ChatCompletion(id='chatcmpl-yCg6t5beFmY2tDZNwdhUuXEkAKrtJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"\\nCertainly. The creation of black holes is a fascinating aspect of astrophysics. Black holes are formed from the remnants of massive stars that undergo a process known as gravitational collapse. Here's a simplified overview of the process:\\n\\n1. **Star Formation**: Stars are born from dense clouds of gas and dust known as nebulae. Over time, gravity causes these clouds to collapse, forming a protostar.\\n\\n2. **Hydrostatic Equilibrium**: The protostar continues to shrink, heating up due to the conversion of gravitational potential energy into kinetic and thermal energy. During this phase, the star maintains a balance between the outward pressure from nuclear fusion reactions in its core and the inward pull of gravity.\\n\\n3. **Nuclear Fuel Depletion**: When the star uses up most of its hydrogen in its core, the fusion reactions slow down and the core shrinks, causing the outer layers of the star to expand into a red giant.\\n\\n4. **Core Collapse**: Once the core's hydrogen is exhausted, it can no longer sustain fusion, and the core collapses further due to gravity. If the core is not massive enough, it becomes a white dwarf. However, if it's more than about 20 times the mass of the Sun, it continues to collapse.\\n\\n5. **Neutron Star Formation**: As the core collapses, electrons and protons combine to form neutrons under immense pressure. This stage results in the formation of a neutron star, which is incredibly dense but stable if its mass is below the Tolman-Oppenheimer-Volkoff limit.\\n\\n6. **Black Hole Formation**: If the original star's core mass is above the Tolman-Oppenheimer-Volkoff limit (approximately 3 solar masses), gravity overcomes the Pauli exclusion principle, and even neutrons cannot withstand the pressure. This leads to the formation of a black hole. The exact process here remains a topic of research.\\n\\nAt this point, the black hole's event horizon forms, and it starts absorbing matter and light. The black hole grows in mass, and its presence affects nearby celestial bodies, such as stars and galaxies. The area surrounding the black hole, known as the accretion disk, is prone to high-energy processes, including the ejection of jets.\", role='assistant', function_call=None, tool_calls=None))], created=1720065353, model='gpt-3.5-turbo', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=458, prompt_tokens=70, total_tokens=528))\n","output_type":"stream"}]},{"cell_type":"code","source":"# pretty format the response\nIPython.display.Markdown(response.choices[0].message.content)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T03:56:28.591504Z","iopub.execute_input":"2024-07-04T03:56:28.591883Z","iopub.status.idle":"2024-07-04T03:56:28.599835Z","shell.execute_reply.started":"2024-07-04T03:56:28.591857Z","shell.execute_reply":"2024-07-04T03:56:28.598669Z"},"scrolled":true,"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\nCertainly. The creation of black holes is a fascinating aspect of astrophysics. Black holes are formed from the remnants of massive stars that undergo a process known as gravitational collapse. Here's a simplified overview of the process:\n\n1. **Star Formation**: Stars are born from dense clouds of gas and dust known as nebulae. Over time, gravity causes these clouds to collapse, forming a protostar.\n\n2. **Hydrostatic Equilibrium**: The protostar continues to shrink, heating up due to the conversion of gravitational potential energy into kinetic and thermal energy. During this phase, the star maintains a balance between the outward pressure from nuclear fusion reactions in its core and the inward pull of gravity.\n\n3. **Nuclear Fuel Depletion**: When the star uses up most of its hydrogen in its core, the fusion reactions slow down and the core shrinks, causing the outer layers of the star to expand into a red giant.\n\n4. **Core Collapse**: Once the core's hydrogen is exhausted, it can no longer sustain fusion, and the core collapses further due to gravity. If the core is not massive enough, it becomes a white dwarf. However, if it's more than about 20 times the mass of the Sun, it continues to collapse.\n\n5. **Neutron Star Formation**: As the core collapses, electrons and protons combine to form neutrons under immense pressure. This stage results in the formation of a neutron star, which is incredibly dense but stable if its mass is below the Tolman-Oppenheimer-Volkoff limit.\n\n6. **Black Hole Formation**: If the original star's core mass is above the Tolman-Oppenheimer-Volkoff limit (approximately 3 solar masses), gravity overcomes the Pauli exclusion principle, and even neutrons cannot withstand the pressure. This leads to the formation of a black hole. The exact process here remains a topic of research.\n\nAt this point, the black hole's event horizon forms, and it starts absorbing matter and light. The black hole grows in mass, and its presence affects nearby celestial bodies, such as stars and galaxies. The area surrounding the black hole, known as the accretion disk, is prone to high-energy processes, including the ejection of jets."},"metadata":{}}]},{"cell_type":"code","source":"CONTENT = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \\\"Unsure about answer\\\" if not sure about the answer.\n\nContext: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n\nQuestion: What was OKT3 originally sourced from?\n\nAnswer:\n\"\"\"\n\nresponse = client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"user\", \"content\": CONTENT},\n    ],\n    temperature=0,\n)\n\nprint(response.choices[0].message.content)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T03:58:07.903743Z","iopub.execute_input":"2024-07-04T03:58:07.904206Z","iopub.status.idle":"2024-07-04T03:58:12.943477Z","shell.execute_reply.started":"2024-07-04T03:58:07.904171Z","shell.execute_reply":"2024-07-04T03:58:12.942329Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\nMice\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 文心一言","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}