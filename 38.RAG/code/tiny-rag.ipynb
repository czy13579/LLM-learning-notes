{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Tiny-RAG\n- 向量化模块\n- 文档加载和切分模块\n- 数据库\n- 向量检索\n- 大模型模块","metadata":{}},{"cell_type":"code","source":"!pip install PyPDF2\n!pip install html2text\n!pip install tiktoken\n!pip install modelscope","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:55:16.771449Z","iopub.execute_input":"2024-08-05T04:55:16.772123Z","iopub.status.idle":"2024-08-05T04:56:21.453670Z","shell.execute_reply.started":"2024-08-05T04:55:16.772091Z","shell.execute_reply":"2024-08-05T04:56:21.452338Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nCollecting html2text\n  Downloading html2text-2024.2.26.tar.gz (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: html2text\n  Building wheel for html2text (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33110 sha256=bf1d7c0ea61159e2207096a399f14d2af8f9e6c0b46f2c209382a1ceb2742d2d\n  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\nSuccessfully built html2text\nInstalling collected packages: html2text\nSuccessfully installed html2text-2024.2.26\nCollecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.7.0\nCollecting modelscope\n  Downloading modelscope-1.17.0-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.25 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.32.3)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (4.66.4)\nRequirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.18)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2024.7.4)\nDownloading modelscope-1.17.0-py3-none-any.whl (5.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: modelscope\nSuccessfully installed modelscope-1.17.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:58:40.171861Z","iopub.execute_input":"2024-08-05T04:58:40.172530Z","iopub.status.idle":"2024-08-05T04:58:54.653963Z","shell.execute_reply.started":"2024-08-05T04:58:40.172474Z","shell.execute_reply":"2024-08-05T04:58:54.652881Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\nDownloading openai-1.38.0-py3-none-any.whl (335 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai\nSuccessfully installed openai-1.38.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install dashscope zhipuai","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:00:22.773733Z","iopub.execute_input":"2024-08-05T05:00:22.774505Z","iopub.status.idle":"2024-08-05T05:00:37.645682Z","shell.execute_reply.started":"2024-08-05T05:00:22.774470Z","shell.execute_reply":"2024-08-05T05:00:37.644619Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting dashscope\n  Downloading dashscope-1.20.3-py3-none-any.whl.metadata (6.6 kB)\nCollecting zhipuai\n  Downloading zhipuai-2.1.4.20230731-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from dashscope) (3.9.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from dashscope) (2.32.3)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from dashscope) (1.7.0)\nRequirement already satisfied: cachetools>=4.2.2 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (4.2.4)\nRequirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (0.27.0)\nRequirement already satisfied: pydantic<3.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (2.5.3)\nRequirement already satisfied: pydantic-core>=2.14.6 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (2.14.6)\nRequirement already satisfied: pyjwt<2.9.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from zhipuai) (2.8.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->zhipuai) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->zhipuai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0,>=1.9.0->zhipuai) (0.6.0)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0,>=1.9.0->zhipuai) (4.9.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->dashscope) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->dashscope) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->dashscope) (1.26.18)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->zhipuai) (1.2.0)\nDownloading dashscope-1.20.3-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading zhipuai-2.1.4.20230731-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: zhipuai, dashscope\nSuccessfully installed dashscope-1.20.3 zhipuai-2.1.4.20230731\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.Embedding","metadata":{}},{"cell_type":"code","source":"%%writefile .env\nOPENAI_API_KEY='sk-7INmRu6iHEope6cJCa462b608aFb4eE281Df64F4E32e95F9'\nOPENAI_BASE_URL='https://threefive.gpt7.link/v1'  # 有些国内的代理商需要加v1，有些不需要\n\nZHIPUAI_API_KEY='68604cc3e382eba3aba03daca6f4f717.fteCwuYKtXWpexN6'\nDASHSCOPE_API_KEY='sk-d4c3f773af5d442c97eb7d9e40479c55'","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:11:50.644009Z","iopub.execute_input":"2024-08-05T05:11:50.644420Z","iopub.status.idle":"2024-08-05T05:11:50.650779Z","shell.execute_reply.started":"2024-08-05T05:11:50.644381Z","shell.execute_reply":"2024-08-05T05:11:50.649794Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Overwriting .env\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom copy import copy\nfrom typing import Dict, List, Optional, Tuple, Union\nimport numpy as np\n\nos.environ['CURL_CA_BUNDLE'] = ''\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\n\nclass BaseEmbeddings:\n    \"\"\"\n    Base class for embeddings\n    \"\"\"\n    def __init__(self, path: str, is_api: bool) -> None:\n        self.path = path\n        self.is_api = is_api\n    \n    def get_embedding(self, text: str, model: str) -> List[float]:\n        raise NotImplementedError\n    \n    @classmethod\n    def cosine_similarity(cls, vector1: List[float], vector2: List[float]) -> float:\n        \"\"\"\n        calculate cosine similarity between two vectors\n        \"\"\"\n        dot_product = np.dot(vector1, vector2)\n        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n        if not magnitude:\n            return 0\n        return dot_product / magnitude\n    \n\nclass OpenAIEmbedding(BaseEmbeddings):\n    \"\"\"\n    class for OpenAI embeddings\n    \"\"\"\n    def __init__(self, path: str = '', is_api: bool = True) -> None:\n        super().__init__(path, is_api)\n        if self.is_api:\n            from openai import OpenAI\n            self.client = OpenAI()\n            self.client.api_key = os.getenv(\"OPENAI_API_KEY\")\n            self.client.base_url = os.getenv(\"OPENAI_BASE_URL\")\n    \n    def get_embedding(self, text: str, model: str = \"text-embedding-3-large\") -> List[float]:\n        if self.is_api:\n            text = text.replace(\"\\n\", \" \")\n            return self.client.embeddings.create(input=[text], model=model).data[0].embedding\n        else:\n            raise NotImplementedError\n\nclass JinaEmbedding(BaseEmbeddings):\n    \"\"\"\n    class for Jina embeddings\n    \"\"\"\n    def __init__(self, path: str = 'jinaai/jina-embeddings-v2-base-zh', is_api: bool = False) -> None:\n        super().__init__(path, is_api)\n        self._model = self.load_model()\n        \n    def get_embedding(self, text: str) -> List[float]:\n        return self._model.encode([text])[0].tolist()\n    \n    def load_model(self):\n        import torch\n        from transformers import AutoModel\n        if torch.cuda.is_available():\n            device = torch.device(\"cuda\")\n        else:\n            device = torch.device(\"cpu\")\n        model = AutoModel.from_pretrained(self.path, trust_remote_code=True).to(device)\n        return model\n\nclass ZhipuEmbedding(BaseEmbeddings):\n    \"\"\"\n    class for Zhipu embeddings\n    \"\"\"\n    def __init__(self, path: str = '', is_api: bool = True) -> None:\n        super().__init__(path, is_api)\n        if self.is_api:\n            from zhipuai import ZhipuAI\n            self.client = ZhipuAI(api_key=os.getenv(\"ZHIPUAI_API_KEY\")) \n    \n    def get_embedding(self, text: str) -> List[float]:\n        response = self.client.embeddings.create(\n        model=\"embedding-2\",\n        input=text,\n        )\n        return response.data[0].embedding\n\nclass DashscopeEmbedding(BaseEmbeddings):\n    \"\"\"\n    class for Dashscope embeddings\n    \"\"\"\n    def __init__(self, path: str = '', is_api: bool = True) -> None:\n        super().__init__(path, is_api)\n        if self.is_api:\n            import dashscope\n            dashscope.api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n            self.client = dashscope.TextEmbedding\n\n    def get_embedding(self, text: str, model: str='text-embedding-v1') -> List[float]:\n        response = self.client.call(\n            model=model,\n            input=text\n        )\n        return response.output['embeddings'][0]['embedding']","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:11:53.688850Z","iopub.execute_input":"2024-08-05T05:11:53.689269Z","iopub.status.idle":"2024-08-05T05:11:53.715109Z","shell.execute_reply.started":"2024-08-05T05:11:53.689235Z","shell.execute_reply":"2024-08-05T05:11:53.714129Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## 2.文档加载和切分","metadata":{}},{"cell_type":"code","source":"\nimport os\nfrom typing import Dict, List, Optional, Tuple, Union\n\nimport PyPDF2\nimport markdown\nimport html2text\nimport json\nfrom tqdm import tqdm\nimport tiktoken\nfrom bs4 import BeautifulSoup\nimport re\n\nenc = tiktoken.get_encoding(\"cl100k_base\")\n\n\nclass ReadFiles:\n    \"\"\"\n    class to read files\n    \"\"\"\n\n    def __init__(self, path: str) -> None:\n        self._path = path\n        self.file_list = self.get_files()\n\n    def get_files(self):\n        # args：dir_path，目标文件夹路径\n        file_list = []\n        for filepath, dirnames, filenames in os.walk(self._path):\n            # os.walk 函数将递归遍历指定文件夹\n            for filename in filenames:\n                # 通过后缀名判断文件类型是否满足要求\n                if filename.endswith(\".md\"):\n                    # 如果满足要求，将其绝对路径加入到结果列表\n                    file_list.append(os.path.join(filepath, filename))\n                elif filename.endswith(\".txt\"):\n                    file_list.append(os.path.join(filepath, filename))\n                elif filename.endswith(\".pdf\"):\n                    file_list.append(os.path.join(filepath, filename))\n        return file_list\n\n    def get_content(self, max_token_len: int = 600, cover_content: int = 150):\n        docs = []\n        # 读取文件内容\n        for file in self.file_list:\n            content = self.read_file_content(file)\n            chunk_content = self.get_chunk(\n                content, max_token_len=max_token_len, cover_content=cover_content)\n            docs.extend(chunk_content)\n        return docs\n\n    @classmethod\n    def get_chunk(cls, text: str, max_token_len: int = 600, cover_content: int = 150):\n        chunk_text = []\n\n        curr_len = 0\n        curr_chunk = ''\n\n        token_len = max_token_len - cover_content\n        lines = text.splitlines()  # 假设以换行符分割文本为行\n\n        for line in lines:\n            line = line.replace(' ', '')\n            line_len = len(enc.encode(line))\n            if line_len > max_token_len:\n                # 如果单行长度就超过限制，则将其分割成多个块\n                num_chunks = (line_len + token_len - 1) // token_len\n                for i in range(num_chunks):\n                    start = i * token_len\n                    end = start + token_len\n                    # 避免跨单词分割\n                    while not line[start:end].rstrip().isspace():\n                        start += 1\n                        end += 1\n                        if start >= line_len:\n                            break\n                    curr_chunk = curr_chunk[-cover_content:] + line[start:end]\n                    chunk_text.append(curr_chunk)\n                # 处理最后一个块\n                start = (num_chunks - 1) * token_len\n                curr_chunk = curr_chunk[-cover_content:] + line[start:end]\n                chunk_text.append(curr_chunk)\n                \n            if curr_len + line_len <= token_len:\n                curr_chunk += line\n                curr_chunk += '\\n'\n                curr_len += line_len\n                curr_len += 1\n            else:\n                chunk_text.append(curr_chunk)\n                curr_chunk = curr_chunk[-cover_content:]+line\n                curr_len = line_len + cover_content\n\n        if curr_chunk:\n            chunk_text.append(curr_chunk)\n\n        return chunk_text\n\n    @classmethod\n    def read_file_content(cls, file_path: str):\n        # 根据文件扩展名选择读取方法\n        if file_path.endswith('.pdf'):\n            return cls.read_pdf(file_path)\n        elif file_path.endswith('.md'):\n            return cls.read_markdown(file_path)\n        elif file_path.endswith('.txt'):\n            return cls.read_text(file_path)\n        else:\n            raise ValueError(\"Unsupported file type\")\n\n    @classmethod\n    def read_pdf(cls, file_path: str):\n        # 读取PDF文件\n        with open(file_path, 'rb') as file:\n            reader = PyPDF2.PdfReader(file)\n            text = \"\"\n            for page_num in range(len(reader.pages)):\n                text += reader.pages[page_num].extract_text()\n            return text\n\n    @classmethod\n    def read_markdown(cls, file_path: str):\n        # 读取Markdown文件\n        with open(file_path, 'r', encoding='utf-8') as file:\n            md_text = file.read()\n            html_text = markdown.markdown(md_text)\n            # 使用BeautifulSoup从HTML中提取纯文本\n            soup = BeautifulSoup(html_text, 'html.parser')\n            plain_text = soup.get_text()\n            # 使用正则表达式移除网址链接\n            text = re.sub(r'http\\S+', '', plain_text) \n            return text\n\n    @classmethod\n    def read_text(cls, file_path: str):\n        # 读取文本文件\n        with open(file_path, 'r', encoding='utf-8') as file:\n            return file.read()\n\n\nclass Documents:\n    \"\"\"\n        获取已分好类的json格式文档\n    \"\"\"\n    def __init__(self, path: str = '') -> None:\n        self.path = path\n    \n    def get_content(self):\n        with open(self.path, mode='r', encoding='utf-8') as f:\n            content = json.load(f)\n        return content\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:56:57.372172Z","iopub.execute_input":"2024-08-05T04:56:57.372502Z","iopub.status.idle":"2024-08-05T04:56:58.986601Z","shell.execute_reply.started":"2024-08-05T04:56:57.372476Z","shell.execute_reply":"2024-08-05T04:56:58.985515Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 3.数据库 && 向量检索","metadata":{}},{"cell_type":"code","source":"import os\nfrom typing import Dict, List, Optional, Tuple, Union\nimport json\nimport numpy as np\nfrom tqdm import tqdm\n\n\nclass VectorStore:\n    def __init__(self, document: List[str] = ['']) -> None:\n        self.document = document\n\n    def get_vector(self, EmbeddingModel: BaseEmbeddings) -> List[List[float]]:\n        \n        self.vectors = []\n        for doc in tqdm(self.document, desc=\"Calculating embeddings\"):\n            self.vectors.append(EmbeddingModel.get_embedding(doc))\n        return self.vectors\n\n    def persist(self, path: str = 'storage'):\n        if not os.path.exists(path):\n            os.makedirs(path)\n        with open(f\"{path}/doecment.json\", 'w', encoding='utf-8') as f:\n            json.dump(self.document, f, ensure_ascii=False)\n        if self.vectors:\n            with open(f\"{path}/vectors.json\", 'w', encoding='utf-8') as f:\n                json.dump(self.vectors, f)\n\n    def load_vector(self, path: str = 'storage'):\n        with open(f\"{path}/vectors.json\", 'r', encoding='utf-8') as f:\n            self.vectors = json.load(f)\n        with open(f\"{path}/doecment.json\", 'r', encoding='utf-8') as f:\n            self.document = json.load(f)\n\n    def get_similarity(self, vector1: List[float], vector2: List[float]) -> float:\n        return BaseEmbeddings.cosine_similarity(vector1, vector2)\n\n    def query(self, query: str, EmbeddingModel: BaseEmbeddings, k: int = 1) -> List[str]:\n        query_vector = EmbeddingModel.get_embedding(query)\n        result = np.array([self.get_similarity(query_vector, vector)\n                          for vector in self.vectors])\n        return np.array(self.document)[result.argsort()[-k:][::-1]].tolist()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:12:09.264486Z","iopub.execute_input":"2024-08-05T05:12:09.264916Z","iopub.status.idle":"2024-08-05T05:12:09.278875Z","shell.execute_reply.started":"2024-08-05T05:12:09.264885Z","shell.execute_reply":"2024-08-05T05:12:09.277915Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## 大模型模块","metadata":{}},{"cell_type":"code","source":"import os\nfrom typing import Dict, List, Optional, Tuple, Union\n\nPROMPT_TEMPLATE = dict(\n    RAG_PROMPT_TEMPALTE=\"\"\"使用以上下文来回答用户的问题。如果你不知道答案，就说你不知道。总是使用中文回答。\n        问题: {question}\n        可参考的上下文：\n        ···\n        {context}\n        ···\n        如果给定的上下文无法让你做出回答，请回答数据库中没有这个内容，你不知道。\n        有用的回答:\"\"\",\n    InternLM_PROMPT_TEMPALTE=\"\"\"先对上下文进行内容总结,再使用上下文来回答用户的问题。如果你不知道答案，就说你不知道。总是使用中文回答。\n        问题: {question}\n        可参考的上下文：\n        ···\n        {context}\n        ···\n        如果给定的上下文无法让你做出回答，请回答数据库中没有这个内容，你不知道。\n        有用的回答:\"\"\"\n)\n\n\nclass BaseModel:\n    def __init__(self, path: str = '') -> None:\n        self.path = path\n\n    def chat(self, prompt: str, history: List[dict], content: str) -> str:\n        pass\n\n    def load_model(self):\n        pass\n\nclass OpenAIChat(BaseModel):\n    def __init__(self, path: str = '', model: str = \"gpt-3.5-turbo-1106\") -> None:\n        super().__init__(path)\n        self.model = model\n\n    def chat(self, prompt: str, history: List[dict], content: str) -> str:\n        from openai import OpenAI\n        client = OpenAI()\n        client.api_key = os.getenv(\"OPENAI_API_KEY\")   \n        client.base_url = os.getenv(\"OPENAI_BASE_URL\")\n        history.append({'role': 'user', 'content': PROMPT_TEMPLATE['RAG_PROMPT_TEMPALTE'].format(question=prompt, context=content)})\n        response = client.chat.completions.create(\n            model=self.model,\n            messages=history,\n            max_tokens=150,\n            temperature=0.1\n        )\n        return response.choices[0].message.content\n\nclass InternLMChat(BaseModel):\n    def __init__(self, path: str = '') -> None:\n        super().__init__(path)\n        self.load_model()\n\n    def chat(self, prompt: str, history: List = [], content: str='') -> str:\n        prompt = PROMPT_TEMPLATE['InternLM_PROMPT_TEMPALTE'].format(question=prompt, context=content)\n        response, history = self.model.chat(self.tokenizer, prompt, history)\n        return response\n\n\n    def load_model(self):\n        import torch\n        from transformers import AutoTokenizer, AutoModelForCausalLM\n        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)\n        self.model = AutoModelForCausalLM.from_pretrained(self.path, torch_dtype=torch.float16, trust_remote_code=True).cuda()\n\nclass DashscopeChat(BaseModel):\n    def __init__(self, path: str = '', model: str = \"qwen-turbo\") -> None:\n        super().__init__(path)\n        self.model = model\n\n    def chat(self, prompt: str, history: List[Dict], content: str) -> str:\n        import dashscope\n        dashscope.api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n        history.append({'role': 'user', 'content': PROMPT_TEMPLATE['RAG_PROMPT_TEMPALTE'].format(question=prompt, context=content)})\n        response = dashscope.Generation.call(\n            model=self.model,\n            messages=history,\n            result_format='message',\n            max_tokens=150,\n            temperature=0.1\n        )\n        return response.output.choices[0].message.content\n    \n\nclass ZhipuChat(BaseModel):\n    def __init__(self, path: str = '', model: str = \"glm-4\") -> None:\n        super().__init__(path)\n        from zhipuai import ZhipuAI\n        self.client = ZhipuAI(api_key=os.getenv(\"ZHIPUAI_API_KEY\"))\n        self.model = model\n\n    def chat(self, prompt: str, history: List[Dict], content: str) -> str:\n        history.append({'role': 'user', 'content': PROMPT_TEMPLATE['RAG_PROMPT_TEMPALTE'].format(question=prompt, context=content)})\n        response = self.client.chat.completions.create(\n            model=self.model,\n            messages=history,\n            max_tokens=150,\n            temperature=0.1\n        )\n        return response.choices[0].message","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:57:05.686508Z","iopub.execute_input":"2024-08-05T04:57:05.687212Z","iopub.status.idle":"2024-08-05T04:57:05.710323Z","shell.execute_reply.started":"2024-08-05T04:57:05.687178Z","shell.execute_reply":"2024-08-05T04:57:05.709284Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## test","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/datawhalechina/llm-cookbook","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:13:06.021807Z","iopub.execute_input":"2024-08-05T05:13:06.022162Z","iopub.status.idle":"2024-08-05T05:13:16.518976Z","shell.execute_reply.started":"2024-08-05T05:13:06.022132Z","shell.execute_reply":"2024-08-05T05:13:16.517911Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Cloning into 'llm-cookbook'...\nremote: Enumerating objects: 4251, done.\u001b[K\nremote: Counting objects: 100% (406/406), done.\u001b[K\nremote: Compressing objects: 100% (214/214), done.\u001b[K\nremote: Total 4251 (delta 253), reused 289 (delta 190), pack-reused 3845\u001b[K\nReceiving objects: 100% (4251/4251), 229.69 MiB | 38.82 MiB/s, done.\nResolving deltas: 100% (2391/2391), done.\nUpdating files: 100% (461/461), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom modelscope import snapshot_download, AutoModel, AutoTokenizer\nimport os\ndownload=False\nif download:\n    model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm2-chat-7b', cache_dir='./', revision='master')\n    model_dir = snapshot_download('jinaai/jina-embeddings-v2-base-zh', cache_dir='./', revision='master')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 使用Dashscope","metadata":{}},{"cell_type":"code","source":"# 建立向量数据库\ndocs = ReadFiles('/kaggle/working/llm-cookbook/content/必修一-Prompt Engineering For Developers').get_content(max_token_len=600, cover_content=150) # 获得data目录下的所有文件内容并分割\nvector = VectorStore(docs)\nembedding = DashscopeEmbedding(path='') # 创建EmbeddingModel\nvector.get_vector(EmbeddingModel=embedding)\nvector.persist(path='storage') # 将向量和文档内容保存到storage目录下，下次再用就可以直接加载本地的数据库","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:14:00.593065Z","iopub.execute_input":"2024-08-05T05:14:00.593955Z","iopub.status.idle":"2024-08-05T05:14:11.032760Z","shell.execute_reply.started":"2024-08-05T05:14:00.593914Z","shell.execute_reply":"2024-08-05T05:14:11.031874Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Calculating embeddings: 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"vector = VectorStore()\n\nvector.load_vector('./storage') # 加载本地的数据库\n\nembedding = DashscopeEmbedding(path='')\n\nquestion = '提示工程是什么？'\n\ncontents = vector.query(question, EmbeddingModel=embedding, k=3)\n\nfor content in contents:\n    print(content)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:17:35.745732Z","iopub.execute_input":"2024-08-05T05:17:35.746828Z","iopub.status.idle":"2024-08-05T05:17:36.636029Z","shell.execute_reply.started":"2024-08-05T05:17:35.746790Z","shell.execute_reply":"2024-08-05T05:17:36.635006Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"面向开发者的提示工程\n本教程为吴恩达《ChatGPTPromptEngineeringforDevelopers》课程中文版，主要内容为指导开发者如何构建Prompt并基于OpenAIAPI构建新的、基于LLM的应用，包括：\n\n书写Prompt的原则\n文本总结（如总结用户评论）；\n文本推断（如情感分类、主题提取）；\n文本转换（如翻译、自动纠错）；\n扩展（如书写邮件）\n\n目录：\n\n简介Introduction@邹雨衡\nPrompt的构建原则Guidelines@邹雨衡\n如何迭代优化PromptItrative@邹雨衡\n文本总结Summarizing@玉琳\n文本推断@长琴\n文本转换Transforming@玉琳\n文本扩展Expand@邹雨衡\n聊天机器人@长琴\n总结@长琴\n\n附1使用ChatGLM学习@宋志学\n\n第一章简介\n作者吴恩达教授\n欢迎来到本课程，我们将为开发人员介绍ChatGPT提示词工程（PromptEngineering）。本课程由IsaFulford教授和我一起授课。Isa是OpenAI的技术团队成员，曾开发过受欢迎的ChatGPT检索插件，并且在教授LLM（LargeLanguageModel,大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用Prompt的OpenAIcookbook。\n互联网上有很多有关提示词（Prompt,本教程中将保留该术语）的材料，例如《30promptseveryonehastoknow》之类的文章。这些文章主要集中在ChatGPT的Web界面上，许多人在使用它执行特定的、通常是一次性的任务。但是，我认为对于开发人员，LLM的更强大功能是能通过API调用，从而快速构建软件应用程序。我认为这方面还没有得到充分的重视。实际上，我们在DeepLearning.AI的姊妹公司AIFund的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到LLMAPI能够让开发人员非常快速地构建应用程序。\n\n恭喜您完成了这门短期课程。\n总的来说，在这门课程中，我们学习了关于Prompt的两个关键原则：\n\n编写清晰具体的指令；\n如果适当的话，给模型一些思考时间。\n\n您还学习了迭代式Prompt开发的方法，并了解了如何找到适合您应用程序的Prompt的过程是非常关键的。\n我们还介绍了许多大型语言模型的功能，包括摘要、推断、转换和扩展。您还学会了如何构建自定义聊天机器人。在这门短期课程中，您学到了很多，希望您喜欢这些学习材料。\n我们希望您能想出一些应用程序的想法，并尝试自己构建它们。请尝试一下并让我们知道您的想法。您可以从一个非常小的项目开始，也许它具有一定的实用价值，也可能完全没有实用价值，只是一些有趣好玩儿的东西。请利用您第一个项目的学习经验来构建更好的第二个项目，甚至更好的第三个项目等。或者，如果您已经有一个更大的项目想法，那就去做吧。\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## 使用RAG\nmodel = DashscopeChat(path='')\nprint(model.chat(question, [], '\\n\\n\\n'.join(contents)))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:18:46.581584Z","iopub.execute_input":"2024-08-05T05:18:46.582213Z","iopub.status.idle":"2024-08-05T05:18:50.587825Z","shell.execute_reply.started":"2024-08-05T05:18:46.582175Z","shell.execute_reply":"2024-08-05T05:18:50.586823Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"提示工程（Prompt Engineering）是指为大型语言模型（LLM）设计和构建指令（Prompt）的过程，以引导模型生成所需的结果。在面向开发者的提示工程中，重点在于指导开发者如何使用OpenAI API构建基于LLM的应用程序。这包括遵循书写Prompt的原则，以及对文本进行总结、推断、转换和扩展等操作。通过迭代优化Prompt，开发者可以提高模型的响应质量和相关性。此外，提示工程还涉及构建聊天机器人，使模型能够与用户进行自然对话。总之，提示工程旨在最大化LLM的能力，使其能够满足各种应用场景的需求。\n","output_type":"stream"}]},{"cell_type":"code","source":"## 不使用RAG\nmodel = DashscopeChat(path='')\nprint(model.chat(question, [], ''))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T05:19:14.308789Z","iopub.execute_input":"2024-08-05T05:19:14.309165Z","iopub.status.idle":"2024-08-05T05:19:16.508241Z","shell.execute_reply.started":"2024-08-05T05:19:14.309135Z","shell.execute_reply":"2024-08-05T05:19:16.507320Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"提示工程是一种设计和实施过程，旨在创建、管理和优化用于生成提示（指导或建议）的系统。这些提示通常用于帮助用户在特定任务或决策过程中更有效地工作。提示工程涉及多个领域，包括人机交互、认知科学、软件工程和设计。通过理解用户需求、任务复杂性以及可用资源，提示工程师可以设计出既有效又易于使用的提示系统，以提高工作效率和用户体验。\n","output_type":"stream"}]}]}